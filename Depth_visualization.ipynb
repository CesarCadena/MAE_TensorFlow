{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started ...\n",
      "Epoch: 0001 cost= 32.855397269\n",
      "Epoch: 0002 cost= 32.468953596\n",
      "Epoch: 0003 cost= 32.398050426\n",
      "Epoch: 0004 cost= 32.352658900\n",
      "Epoch: 0005 cost= 32.280002741\n",
      "Epoch: 0006 cost= 32.252218595\n",
      "Epoch: 0007 cost= 32.189153268\n",
      "Epoch: 0008 cost= 32.144255458\n",
      "Epoch: 0009 cost= 32.115303418\n",
      "Epoch: 0010 cost= 32.069611579\n",
      "saved the vae model weights to vae_models/depth_1_epochs/model\n"
     ]
    }
   ],
   "source": [
    "# %load VAE_depth.py\n",
    "#This is VAE_depth script \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.4\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# Initialization Function\n",
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "    \"\"\" Xavier initialization of network weights\"\"\"\n",
    "    # https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "    # return tensors\n",
    "    return tf.random_uniform((fan_in, fan_out), #  shape of the weights\n",
    "                             minval=low, maxval=high, # here is the range \n",
    "                             dtype=tf.float32) # here is the type \n",
    "\n",
    "# Variational Auto Encoder \n",
    "class VariationalAutoencoder(object):\n",
    "    \n",
    "    \"\"\" Based on See \"Auto-Encoding Variational Bayes\" by Kingma and Welling\n",
    "    \"\"\"\n",
    "    def __init__(self, network_architecture,\n",
    "                 transfer_fct=tf.nn.relu,learning_rate=1e-3,batch_size=100):\n",
    "        \n",
    "        \n",
    "        self.network_architecture=network_architecture# which is a dictionary \n",
    "        self.transfer_fct=transfer_fct\n",
    "        self.learning_rate=learning_rate\n",
    "        self.batch_size=batch_size\n",
    "        # tf Graph input\n",
    "        self.x=tf.placeholder(tf.float32,[None, network_architecture[\"n_input\"]])\n",
    "        self.mask=tf.placeholder(tf.float32,[None, network_architecture[\"n_input\"]])\n",
    "        # Create auotencoder \n",
    "        self.create_network()\n",
    "        # define loss function based on variational upper bound \n",
    "        # and corresponding optimizer \n",
    "        self.create_loss_optimizer()\n",
    "        # initial the tensorflow variables \n",
    "        init=tf.global_variables_initializer()\n",
    "        self.saver_d=tf.train.Saver()\n",
    "        self.sess=tf.Session(config=config)\n",
    "        self.sess.run(init)\n",
    "    \n",
    "    \n",
    "            \n",
    "    def initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "                            n_hidden_gener_1,  n_hidden_gener_2, \n",
    "                            n_input, n_z):\n",
    "        \n",
    "        # create a dictionary of tensor variables \n",
    "        all_weights = dict()\n",
    "        # recognition  network\n",
    "        all_weights['weights_recog'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_2, n_z))}\n",
    "        all_weights['biases_recog'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "        \n",
    "        # generate network \n",
    "        all_weights['weights_gener'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_2, n_input))}\n",
    "        all_weights['biases_gener'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "        return all_weights\n",
    "    \n",
    "    def create_network(self):\n",
    "        # create tensor variables for  weights and bias\n",
    "        network_weights=self.initialize_weights(**self.network_architecture) \n",
    "        # pass architecture parameters \n",
    "        # network_architecture is a dictionary \n",
    "        \n",
    "        \n",
    "        # recognition network :\n",
    "        #input: data x shape [batch_size,n_x]\n",
    "        #output : mean of z , log(variance^2) shape [batch_size,n_z]\n",
    "        # pass variables to network \n",
    "        self.z_mean, self.z_log_sigma_sq = \\\n",
    "            self.recognition_network(network_weights[\"weights_recog\"], \n",
    "                                     network_weights[\"biases_recog\"])\n",
    "            \n",
    "        n_z = self.network_architecture[\"n_z\"]# dimension of z\n",
    "        \n",
    "        \n",
    "        eps = tf.random_normal((self.batch_size, n_z), 0, 1, dtype=tf.float32) \n",
    "        # standard Normal\n",
    "        # z = z_mean + z_sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n",
    "        #shape [batch_size,n_z]\n",
    "        \n",
    "        # Generate network :\n",
    "        # input z\n",
    "        # output mean of pixels shape[batch_Size,n_x]\n",
    "        # multivariant Gaussian Distribution\n",
    "        self.x_reconstr_mean = \\\n",
    "            self.generator_network(network_weights[\"weights_gener\"],\n",
    "                                   network_weights[\"biases_gener\"])\n",
    "    \n",
    "    def recognition_network(self, weights, biases):\n",
    "        # Generate probabilistic encoder (recognition network), which\n",
    "        # maps inputs onto a normal distribution in latent space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        z_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "                        biases['out_mean'])\n",
    "        \n",
    "        z_log_sigma_sq =\\\n",
    "            tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "                   biases['out_log_sigma'])\n",
    "            \n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "    \n",
    "    # use variables to buld generate network \n",
    "    def generator_network(self, weights, biases):\n",
    "        # Generate probabilistic decoder (decoder network), which\n",
    "        # maps points in latent space onto a Bernoulli distribution in data space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        \n",
    "        # depth estimation mean \n",
    "        x_reconstr_mean = \\\n",
    "           tf.nn.relu(tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "                                 biases['out_mean']))\n",
    "            \n",
    "        #x_reconstr_sigma= \\\n",
    "        #     tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "        #                        biases['out_log_sigma'])\n",
    "            \n",
    "        return x_reconstr_mean\n",
    "    \n",
    "    def create_loss_optimizer(self):\n",
    "        # The loss is composed of two terms:\n",
    "        \n",
    "        # 1.) The reconstruction loss (the negative log probability\n",
    "        #     of the input under the reconstructed Bernoulli/Gaussian distribution \n",
    "        #     induced by the decoder in the data space).\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for reconstructing the input when the activation in latent\n",
    "        #     is given.\n",
    "        # Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "        # Assuem identity gaussian \n",
    "        \n",
    "        # loss from generative data \n",
    "        \n",
    "        # 1) bernouli distribution\n",
    "        \"\"\"\n",
    "        reconstr_loss =-tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "                           axis=1)\n",
    "        \"\"\"\n",
    "        # 1) gaussian distribution\n",
    "        reconstr_error=(self.x-self.x_reconstr_mean)*self.mask\n",
    "        reconstr_loss=tf.reduce_sum(tf.square(reconstr_error),axis=1)\n",
    "          \n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        #     closed form of  KL  divergence with gaussian distribution\n",
    "        latent_loss=-0.5*tf.reduce_sum(1+self.z_log_sigma_sq \n",
    "                                           -tf.square(self.z_mean) \n",
    "                                           -tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        \n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss) # average over batch\n",
    "        # Use ADAM optimizer\n",
    "        \n",
    "        self.optimizer = \\\n",
    "            tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "    def partial_fit(self, X):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x: X})\n",
    "        return cost\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})\n",
    "    \n",
    "    def save(self, check_point_file = 'model.ckpt'):\n",
    "        save_path = self.saver_d.save(self.sess, check_point_file) # Saves the weights (not the graph)\n",
    "        print(\"saved the vae model weights to \"+save_path)\n",
    "        # to load it,\n",
    "        \n",
    "    def load(self, check_point_file = 'model.ckpt'):\n",
    "        self.saver_d.restore(self.sess, check_point_file)\n",
    "        print(\"loaded model weights from \"+check_point_file)\n",
    "        \n",
    "    def train(self, batch_size=100,training_epochs=1,display_step=1):\n",
    "        print(\"training started ...\")\n",
    "        train_indices=range(n_samples)\n",
    "        \n",
    "        for epoch in range(training_epochs):\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(n_samples / batch_size)\n",
    "            perm_indices=np.random.permutation(train_indices)\n",
    "        # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "                \n",
    "                offset=(i*batch_size)%(n_samples-batch_size)\n",
    "                # mnist data  batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "                batch_indices=perm_indices[offset:(offset+batch_size)]\n",
    "                \n",
    "                batch_xs=Depth_input[batch_indices]\n",
    "                batch_mask=Depthmask_input[batch_indices]\n",
    "            # Fit training using batch data\n",
    "                _,cost=self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x:batch_xs,self.mask:batch_mask})\n",
    "              \n",
    "            # Compute average loss\n",
    "                avg_cost += cost / n_samples * batch_size\n",
    "        # Display logs per epoch step\n",
    "            if epoch % display_step == 0:\n",
    "                print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                      \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "\n",
    "# Load depth data \n",
    "depth_data=np.load(\"../Data/depth_data.npy\")\n",
    "depthmask_data=np.load(\"../Data/depth_mask.npy\")\n",
    "Depth_input=depth_data[:,:,:,0].reshape(-1,1080)\n",
    "Depthmask_input=depthmask_data[:,:,:,0].reshape(-1,1080)\n",
    "#Depth_input=np.transpose(depth_data,(0,2,1,3))[:,:,:,0].reshape(-1,1080)\n",
    "n_samples=Depth_input.shape[0]\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"depth\"):\n",
    "    network_architecture = \\\n",
    "        dict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "         n_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "         n_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "         n_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "         n_input=1080, # MNIST data input (img shape: 28*28)\n",
    "         n_z=50)  # dimensionality of latent space\n",
    "    vae = VariationalAutoencoder(network_architecture,learning_rate=1e-3,batch_size=100)\n",
    "\n",
    "\n",
    "train_new_model =True\n",
    "if train_new_model:    \n",
    "    vae.train(batch_size=100,training_epochs=10)\n",
    "    vae.save(\"vae_models/depth_1_epochs/model\")\n",
    "else:\n",
    "    vae.load(\"vae_models/depth_1_epochs/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        ,  0.05544548,  0.05381951, ...,  0.18291567,\n",
       "        0.18345258,  0.17574692])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Depth_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "prediction=vae.sess.run(vae.x_reconstr_mean,feed_dict={vae.x:Depth_input[0:100,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.18057153, 0.17727605,\n",
       "       0.17322063], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181df5c4e0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACHCAYAAAAGEqJQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxadhWcY3TfDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181b321c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Depth_input[0].reshape(18,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181b113160>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACHCAYAAAAGEqJQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18205d9198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(prediction[0].reshape(18,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
