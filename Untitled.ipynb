{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load VAE_RGB.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.4\n",
    "tf.reset_default_graph()\n",
    "num_epochs=1\n",
    "rgbpath=\"vae_models/rgb_\"+str(num_epochs)+\"_epochs/model\"\n",
    "batch_size=100\n",
    "\n",
    "# Initialization\n",
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "    \"\"\" Xavier initialization of network weights\"\"\"\n",
    "    # https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "    # return tensors\n",
    "    return tf.random_uniform((fan_in, fan_out), #  shape of the weights\n",
    "                             minval=low, maxval=high, # here is the range \n",
    "                             dtype=tf.float32) # here is the type \n",
    "\n",
    "class VariationalAutoencoder(object):\n",
    "    \n",
    "    \"\"\" Based on See \"Auto-Encoding Variational Bayes\" by Kingma and Welling\n",
    "    \"\"\"\n",
    "    def __init__(self, network_architecture,\n",
    "                 transfer_fct=tf.nn.softplus,learning_rate=1e-3,batch_size=batch_size):\n",
    "        \n",
    "        \n",
    "        self.network_architecture=network_architecture# which is a dictionary \n",
    "        self.transfer_fct=transfer_fct\n",
    "        self.learning_rate=learning_rate\n",
    "        self.batch_size=batch_size\n",
    "        # tf Graph input\n",
    "        self.x=tf.placeholder(tf.float32,[None, network_architecture[\"n_input\"]])\n",
    "        \n",
    "        \n",
    "        # Create auotencoder \n",
    "        self.create_network()\n",
    "        # define loss function based on variational upper bound \n",
    "        # and corresponding optimizer \n",
    "        self.create_loss_optimizer()\n",
    "        # initial the tensorflow variables \n",
    "        init=tf.global_variables_initializer()\n",
    "        self.saver_r=tf.train.Saver()\n",
    "        self.sess=tf.Session(config=config)\n",
    "        self.sess.run(init)\n",
    "    \n",
    "            \n",
    "    def initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "                            n_hidden_gener_1,  n_hidden_gener_2, \n",
    "                            n_input, n_z):\n",
    "        \n",
    "        # create a dictionary of tensor variables \n",
    "        all_weights = dict()\n",
    "        \n",
    "        # recognition  network\n",
    "        all_weights['weights_recog'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_2, n_z))}\n",
    "        all_weights['biases_recog'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "        \n",
    "        # generate network \n",
    "        all_weights['weights_gener'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_2, n_input))}\n",
    "        all_weights['biases_gener'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "        return all_weights\n",
    "        \n",
    "        \n",
    "    def create_network(self):\n",
    "        # create tensor variables for  weights and bias\n",
    "        network_weights=self.initialize_weights(**self.network_architecture) \n",
    "        # pass architecture parameters \n",
    "        # network_architecture is a dictionary \n",
    "        \n",
    "        \n",
    "        # recognition network :\n",
    "        #input: data x shape [batch_size,n_x]\n",
    "        #output : mean of z , log(variance^2) shape [batch_size,n_z]\n",
    "        # pass variables to network \n",
    "        self.z_mean, self.z_log_sigma_sq = \\\n",
    "            self.recognition_network(network_weights[\"weights_recog\"], \n",
    "                                     network_weights[\"biases_recog\"])\n",
    "            \n",
    "        n_z = self.network_architecture[\"n_z\"]# dimension of z\n",
    "        \n",
    "        \n",
    "        eps = tf.random_normal((self.batch_size, n_z), 0, 1, dtype=tf.float32) \n",
    "        # standard Normal\n",
    "        # z = z_mean + z_sigma*epsilon\n",
    "        \n",
    "        self.z = tf.add(self.z_mean, tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n",
    "        #shape [batch_size,n_z]\n",
    "        \n",
    "        # Generate network :\n",
    "        # input z\n",
    "        # output mean of pixels shape[batch_Size,n_x]\n",
    "        # multivariant Gaussian Distribution\n",
    "        self.x_reconstr_mean = \\\n",
    "            self.generator_network(network_weights[\"weights_gener\"],\n",
    "                                   network_weights[\"biases_gener\"])\n",
    "            \n",
    "\n",
    "    #  use the variables to build the network      \n",
    "    def recognition_network(self, weights, biases):\n",
    "        # Generate probabilistic encoder (recognition network), which\n",
    "        # maps inputs onto a normal distribution in latent space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        z_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "                        biases['out_mean'])\n",
    "        \n",
    "        z_log_sigma_sq =\\\n",
    "            tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "                   biases['out_log_sigma'])\n",
    "            \n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "    \n",
    "    # use variables to buld generate network \n",
    "    def generator_network(self, weights, biases):\n",
    "        # Generate probabilistic decoder (decoder network), which\n",
    "        # maps points in latent space onto a Bernoulli distribution in data space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        \n",
    "        x_reconstr_mean = \\\n",
    "            tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "                                 biases['out_mean']))\n",
    "            \n",
    "        x_reconstr_sigma= \\\n",
    "             tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "                                biases['out_log_sigma'])\n",
    "            \n",
    "        return x_reconstr_mean\n",
    "    \n",
    "    \n",
    "    def create_loss_optimizer(self):\n",
    "        # The loss is composed of two terms:\n",
    "        \n",
    "        # 1.) The reconstruction loss (the negative log probability\n",
    "        #     of the input under the reconstructed Bernoulli/Gaussian distribution \n",
    "        #     induced by the decoder in the data space).\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for reconstructing the input when the activation in latent\n",
    "        #     is given.\n",
    "        # Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "        # Assuem identity gaussian \n",
    "        \n",
    "        # loss from generative data \n",
    "        \n",
    "        # 1) bernouli distribution\n",
    "        \"\"\"\n",
    "        reconstr_loss =-tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "                           axis=1)\n",
    "        \"\"\"\n",
    "        # 1) gaussian distribution\n",
    "        reconstr_error=self.x-self.x_reconstr_mean\n",
    "        reconstr_loss=tf.reduce_sum(tf.square(reconstr_error),axis=1)\n",
    "         \n",
    "            \n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        #     closed form of  KL  divergence with gaussian distribution\n",
    "        latent_loss=-0.5*tf.reduce_sum(1+self.z_log_sigma_sq \n",
    "                                           -tf.square(self.z_mean) \n",
    "                                           -tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        \n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss) # average over batch\n",
    "        # Use ADAM optimizer\n",
    "        \n",
    "        self.optimizer = \\\n",
    "            tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "\n",
    "    def partial_fit(self, X):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x: X})\n",
    "        return cost\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n",
    "    \n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})\n",
    "    \n",
    "    \n",
    "    def save(self, check_point_file = 'model.ckpt'):\n",
    "        save_path = self.saver_r.save(self.sess, check_point_file) # Saves the weights (not the graph)\n",
    "        print(\"saved the vae model weights to \"+save_path)\n",
    "        # to load it,\n",
    "        \n",
    "        \n",
    "    def load(self, check_point_file = 'model.ckpt'):\n",
    "        self.saver_r.restore(self.sess, check_point_file)\n",
    "        print(\"loaded model weights from \"+check_point_file)\n",
    "        \n",
    "    \n",
    "def train(vae, batch_size, training_epochs, display_step=1):\n",
    "    print(\"training started ...\")\n",
    "    train_indices=range(n_samples)\n",
    "        \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples/batch_size)\n",
    "        perm_indices=np.random.permutation(train_indices)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "                \n",
    "            offset=(i*batch_size)%(n_samples-batch_size)\n",
    "                # mnist data  batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "            batch_indices=perm_indices[offset:(offset+batch_size)]\n",
    "                \n",
    "            batch_xs=RGB_input[batch_indices]\n",
    "            # Fit training using batch data\n",
    "            cost =vae.partial_fit(batch_xs)\n",
    "            # Compute average loss\n",
    "            avg_cost += cost/n_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                    \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "##  Load Data \n",
    "RGB_data=np.load(\"../Data/rgb_data.npy\")\n",
    "R_data=RGB_data[:,:,:,0].reshape(-1,1080)\n",
    "G_data=RGB_data[:,:,:,1].reshape(-1,1080)\n",
    "B_data=RGB_data[:,:,:,2].reshape(-1,1080)\n",
    "RGB_input=np.concatenate((R_data,G_data,B_data),axis=1)\n",
    "n_samples=RGB_input.shape[0]\n",
    "\n",
    "with tf.variable_scope(\"RGB\"):\n",
    "    network_architecture = \\\n",
    "        dict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "         n_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "         n_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "         n_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "         n_input=3*1080, # MNIST data input (img shape: 28*28)\n",
    "         n_z=50)  # dimensionality of latent space\n",
    "    vae =VariationalAutoencoder(network_architecture,learning_rate=0.001,batch_size=batch_size)\n",
    "    train_new_model =True\n",
    "    if train_new_model:    \n",
    "       train(vae,batch_size=100,training_epochs=num_epochs)\n",
    "       vae.save(rgbpath)\n",
    "    else:\n",
    "       vae.load(rgbpath)\n",
    "\n",
    "vae.sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
