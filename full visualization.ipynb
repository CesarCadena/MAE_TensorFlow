{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vae_models/depth_5_epochs/model\n",
      "loaded model weights from models/depth_5_epochs/model\n",
      "INFO:tensorflow:Restoring parameters from vae_models/RGB_1_epochs/model\n",
      "loaded model weights from models/RGB_1_epochs/model\n",
      "INFO:tensorflow:Restoring parameters from vae_models/sem_1_epochs/model\n",
      "loaded model weights from models/sem_1_epochs/model\n",
      "INFO:tensorflow:Restoring parameters from vae_models/full_1_epochs/model\n",
      "loaded the vae model weights frommodels/full_1_epochs/model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACHCAYAAAAGEqJQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18200f2400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load VAE_full.py\n",
    "#This is VAE_depth script \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.4\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "\t\"\"\" Xavier initialization of network weights\"\"\"\n",
    "\t# https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "\tlow = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "\thigh = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "\t# return tensors\n",
    "\treturn tf.random_uniform((fan_in, fan_out), #  shape of the weights\n",
    "\t\t\t\t\t\t\t minval=low, maxval=high, # here is the range \n",
    "\t\t\t\t\t\t\t dtype=tf.float32) # here is the type\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(object):\n",
    "\t\"\"\" Based on See \"Auto-Encoding Variational Bayes\" by Kingma and Welling\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, network_architecture,\n",
    "\t\t\t\t transfer_fct=tf.nn.softplus,learning_rate=1e-3,batch_size=100):\n",
    "\t\tself.network_architecture=network_architecture# which is a dictionary \n",
    "\t\tself.transfer_fct=transfer_fct\n",
    "\t\tself.learning_rate=learning_rate\n",
    "\t\tself.batch_size=batch_size\n",
    "\t\t# tf Graph input\n",
    "\t\tself.x=tf.placeholder(tf.float32,[None, network_architecture[\"n_input\"]])\n",
    "\t\t# Create auotencoder \n",
    "\t\tself.create_network()\n",
    "\t\t# define loss function based on variational upper bound \n",
    "\t\t# and corresponding optimizer \n",
    "\t\tself.create_loss_optimizer()\n",
    "\t\t#self.saver=tf.train.Saver()\n",
    "\n",
    "\n",
    "\tdef initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "\t\t\t\t\t\t\tn_hidden_gener_1,  n_hidden_gener_2, \n",
    "\t\t\t\t\t\t\tn_input, n_z):\n",
    "\t\t# create a dictionary of tensor variables \n",
    "\t\tall_weights = dict()\n",
    "\t\t# recognition  network\n",
    "\t\tall_weights['weights_recog'] = {\n",
    "\t\t\t'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "\t\t\t'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "\t\t\t'out_mean': tf.Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_2, n_z))}\n",
    "\t\tall_weights['biases_recog'] = {\n",
    "\t\t\t'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "\t\t\t'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "\t\t\t'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "\t\t# generate network \n",
    "\t\tall_weights['weights_gener'] = {\n",
    "\t\t\t'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "\t\t\t'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "\t\t\t'out_mean': tf.Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_2, n_input))}\n",
    "\t\tall_weights['biases_gener'] = {\n",
    "\t\t\t'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "\t\t\t'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "\t\t\t'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "\t\treturn all_weights\n",
    "\t\n",
    "\tdef create_network(self):\n",
    "\t\t# create tensor variables for  weights and bias\n",
    "\t\tself.network_weights=self.initialize_weights(**self.network_architecture) \n",
    "\t\t# network_weights  is a dictionary \n",
    "\t\t# pass architecture parameters \n",
    "\t\t# network_architecture is a dictionary \n",
    "\n",
    "\t\t# recognition network :\n",
    "\t\t#input: data x shape [batch_size,n_x]\n",
    "\t\t#output : mean of z , log(variance^2) shape [batch_size,n_z]\n",
    "\t\t# pass variables to network \n",
    "\t\tself.z_mean, self.z_log_sigma_sq = \\\n",
    "\t\t\tself.recognition_network(self.network_weights[\"weights_recog\"], \n",
    "\t\t\t\t\t\t\t\t\t self.network_weights[\"biases_recog\"])\n",
    "\t\t\t\n",
    "\t\tn_z = self.network_architecture[\"n_z\"]# dimension of z\n",
    "\t\t\n",
    "\t\t\n",
    "\t\teps = tf.random_normal((self.batch_size, n_z), 0, 1, dtype=tf.float32) \n",
    "\t\t# standard Normal\n",
    "\t\t# z = z_mean + z_sigma*epsilon\n",
    "\t\t\n",
    "\t\tself.z = tf.add(self.z_mean, tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n",
    "\t\t#shape [batch_size,n_z]\n",
    "\t\t\n",
    "\t\t# Generate network :\n",
    "\t\t# input z\n",
    "\t\t# output mean of pixels shape[batch_Size,n_x]\n",
    "\t\t# multivariant Gaussian Distribution\n",
    "\t\tself.x_reconstr_mean = \\\n",
    "\t\t\tself.generator_network(self.network_weights[\"weights_gener\"],\n",
    "\t\t\t\t\t\t\t\t   self.network_weights[\"biases_gener\"])\n",
    "\t\n",
    "\tdef recognition_network(self, weights, biases):\n",
    "\t\t# Generate probabilistic encoder (recognition network), which\n",
    "\t\t# maps inputs onto a normal distribution in latent space.\n",
    "\t\t# The transformation is parametrized and can be learned.\n",
    "\t\tlayer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b1'])) \n",
    "\t\tlayer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b2'])) \n",
    "\t\tz_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "\t\t\t\t\t\tbiases['out_mean'])\n",
    "\t\t\n",
    "\t\tz_log_sigma_sq =\\\n",
    "\t\t\ttf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "\t\t\t\t   biases['out_log_sigma'])\n",
    "\t\t\t\n",
    "\t\treturn (z_mean, z_log_sigma_sq)\n",
    "\t\n",
    "\t# use variables to buld generate network \n",
    "\tdef generator_network(self, weights, biases):\n",
    "\t\t# Generate probabilistic decoder (decoder network), which\n",
    "\t\t# maps points in latent space onto a Bernoulli distribution in data space.\n",
    "\t\t# The transformation is parametrized and can be learned.\n",
    "\t\tlayer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b1'])) \n",
    "\t\tlayer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b2'])) \n",
    "\t\t\n",
    "\t\t# depth estimation mean \n",
    "\t\tx_reconstr_mean = \\\n",
    "\t\t   tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "\t\t\t\t\t\t\t\t biases['out_mean'])\n",
    "\t\t#x_reconstr_sigma= \\\n",
    "\t\t#     tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "\t\t#                        biases['out_log_sigma'])\n",
    "\t\treturn x_reconstr_mean\n",
    "\t\n",
    "\tdef create_loss_optimizer(self):\n",
    "\t\t# The loss is composed of two terms:\n",
    "\t\t\n",
    "\t\t# 1.) The reconstruction loss (the negative log probability\n",
    "\t\t#     of the input under the reconstructed Bernoulli/Gaussian distribution \n",
    "\t\t#     induced by the decoder in the data space).\n",
    "\t\t#     This can be interpreted as the number of \"nats\" required\n",
    "\t\t#     for reconstructing the input when the activation in latent\n",
    "\t\t#     is given.\n",
    "\t\t# Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "\t\t# Assuem identity gaussian \n",
    "\t\t\n",
    "\t\t# loss from generative data \n",
    " \n",
    "\t\t# 1) bernouli distribution\n",
    "\t\t\"\"\"\n",
    "\t\treconstr_loss =-tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "\t\t\t\t\t\t   + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "\t\t\t\t\t\t   axis=1)\n",
    "\t\t\"\"\"\n",
    "\t\t# 1) gaussian distribution\n",
    "\t\treconstr_error=self.x-self.x_reconstr_mean\n",
    "\t\treconstr_loss=tf.reduce_sum(tf.square(reconstr_error),axis=1)\n",
    "\t\t# 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "\t\t##    between the distribution in latent space induced by the encoder on \n",
    "\t\t#     the data and some prior. This acts as a kind of regularizer.\n",
    "\t\t#     This can be interpreted as the number of \"nats\" required\n",
    "\t\t#     for transmitting the the latent space distribution given\n",
    "\t\t#     the prior.\n",
    "\t\t#     closed form of  KL  divergence with gaussian distribution\n",
    "\t\tlatent_loss=-0.5*tf.reduce_sum(1+self.z_log_sigma_sq \n",
    "\t\t\t\t\t\t\t\t\t\t   -tf.square(self.z_mean) \n",
    "\t\t\t\t\t\t\t\t\t\t   -tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "\t\tself.cost = tf.reduce_mean(reconstr_loss + latent_loss) # average over batch\n",
    "\t\t# Use ADAM optimizer\n",
    "\t\tself.optimizer = \\\n",
    "\t\t\ttf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\t\t\t\n",
    "\n",
    "\tdef partial_fit(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tTrain model based on mini-batch of input data.\n",
    "\t\tReturn cost of mini-batch.\n",
    "\t\t\"\"\"\n",
    "\t\topt,cost = sess.run((self.optimizer, self.cost), \n",
    "\t\t\t\t\t\t\t\t  feed_dict={self.x: X})\n",
    "\t\treturn cost\n",
    "\n",
    "\n",
    "\tdef train(self, batch_size=100, training_epochs=10, display_step=1):\n",
    "\t\tprint(\"training started ...\")\n",
    "\t\ttrain_indices=range(n_samples)\n",
    "\t\tfor epoch in range(training_epochs):\n",
    "\t\t\tavg_cost = 0.\n",
    "\t\t\ttotal_batch = int(n_samples / batch_size)\n",
    "\t\t\tperm_indices=np.random.permutation(train_indices)\n",
    "\t\t# Loop over all batches\n",
    "\t\t\tfor i in range(total_batch):\n",
    "\t\t\t\toffset=(i*batch_size)%(n_samples-batch_size)\n",
    "\t\t\t\t# mnist data  batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "\t\t\t\tbatch_indices=perm_indices[offset:(offset+batch_size)]\n",
    "\t\t\t\t# feed the data for full models \n",
    "\t\t\t\tbatch_xs=z_in[batch_indices]\n",
    "\t\t\t# Fit training using batch data\n",
    "\t\t\t\tcost = self.partial_fit(batch_xs)\n",
    "\t\t\t# Compute average loss\n",
    "\t\t\t\tavg_cost += cost/n_samples*batch_size\n",
    "\t\t# Display logs per epoch step\n",
    "\t\t\tif epoch % display_step == 0:\n",
    "\t\t\t\tprint(\"Epoch:\", '%04d' % (epoch+1), \n",
    "\t\t\t\t\t  \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Build  network for depth channel\n",
    "with tf.variable_scope(\"depth\"):\n",
    "\tnetwork_architecture_depth= \\\n",
    "\t   dict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "\t\t n_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "\t\t n_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "\t\t n_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "\t\t n_input=1080, # MNIST data input (img shape: 28*28)\n",
    "\t\t n_z=50)  # dimensionality of latent space\n",
    "\tvae_depth=VariationalAutoencoder(network_architecture_depth,learning_rate=0.001,batch_size=100)\n",
    "\n",
    "listvar=vae_depth.network_weights\n",
    "var_depth=(list(listvar['weights_recog'].values())\n",
    "\t+list(listvar['biases_recog'].values())\n",
    "\t+list(listvar['weights_gener'].values())\n",
    "\t+list(listvar['biases_gener'].values()))\n",
    "saver_depth=tf.train.Saver(var_depth)\n",
    "\n",
    "\n",
    "# Build network for semantics  channel\n",
    "with tf.variable_scope(\"RGB\"):\n",
    "\tnetwork_architecture_rgb= \\\n",
    "\t\tdict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "\t\t\tn_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "\t\t\tn_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "\t\t\tn_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "\t\t\tn_input=1080*3, # MNIST data input (img shape: 28*28)\n",
    "\t\t\tn_z=50)  # dimensionality of latent space\n",
    "\tvae_rgb=VariationalAutoencoder(network_architecture_rgb,learning_rate=0.001,batch_size=100)\n",
    "    \n",
    "listvar2=vae_rgb.network_weights\n",
    "var_rgb=(list(listvar2['weights_recog'].values())\n",
    "\t+list(listvar2['biases_recog'].values())\n",
    "\t+list(listvar2['weights_gener'].values())\n",
    "\t+list(listvar2['biases_gener'].values()))\n",
    "saver_rgb=tf.train.Saver(var_rgb)\n",
    "\n",
    "\n",
    "# Build network for semantic channels\n",
    "with tf.variable_scope(\"Sem\"):\n",
    "\tnetwork_architecture_Sem = \\\n",
    "\t\tdict(n_hidden_recog_1=2000, # 1st layer encoder neurons\n",
    "\t\t n_hidden_recog_2=2000, # 2nd layer encoder neurons\n",
    "\t\t n_hidden_gener_1=2000, # 1st layer decoder neurons\n",
    "\t\t n_hidden_gener_2=2000, # 2nd layer decoder neurons\n",
    "\t\t n_input=5400, # MNIST data input (img shape: 28*28)\n",
    "\t\t n_z=100)  # dimensionality of latent space\n",
    "\tvae_Sem=VariationalAutoencoder(network_architecture_Sem,learning_rate=1e-4,batch_size=100)\n",
    "\n",
    "listvar3=vae_Sem.network_weights\n",
    "var_Sem=(list(listvar3['weights_recog'].values())\n",
    "\t+list(listvar3['biases_recog'].values())\n",
    "\t+list(listvar3['weights_gener'].values())\n",
    "\t+list(listvar3['biases_gener'].values()))\n",
    "saver_Sem=tf.train.Saver(var_Sem)\n",
    "\n",
    "\n",
    "########################    Start build  shared information fusion   #############################\n",
    "\n",
    "\n",
    "\n",
    "########################    Start build  shared information fusion   #############################\n",
    "############## Load data ####################\n",
    "depth_data=np.load(\"../Data/depth_data.npy\")\n",
    "Depth_input=np.transpose(depth_data,(0,2,1,3))[:,:,:,0].reshape(-1,1080)# shape [size,1080]\n",
    "\n",
    "RGB_data=np.load(\"../Data/rgb_data.npy\")\n",
    "R_data=RGB_data[:,:,:,0].reshape(-1,1080)\n",
    "G_data=RGB_data[:,:,:,1].reshape(-1,1080)\n",
    "B_data=RGB_data[:,:,:,2].reshape(-1,1080)\n",
    "RGB_input=np.concatenate((R_data,G_data,B_data),axis=1) #shape[size,3*1080]\n",
    "\n",
    "Sem_data=np.load(\"../Data/sem_data.npy\")\n",
    "Sem_input=np.transpose(Sem_data,(0,2,1,3))\n",
    "Ground_input=Sem_input[:,:,:,0].reshape(-1,1080)\n",
    "Objects_input=Sem_input[:,:,:,1].reshape(-1,1080)\n",
    "Building_input=Sem_input[:,:,:,2].reshape(-1,1080)\n",
    "Vegetation_input=Sem_input[:,:,:,3].reshape(-1,1080)\n",
    "Sky_input=Sem_input[:,:,:,4].reshape(-1,1080)\n",
    "Sem_input=np.concatenate((Ground_input,Objects_input,\n",
    "\t\t\t\t\t\t  Building_input,Vegetation_input,Sky_input),\n",
    "\t\t\t\t\t\t  axis=1)# shape[size,5*1080]\n",
    "\n",
    "n_samples=Sem_input.shape[0] # size \n",
    "############## Finish Load data ####################\n",
    "\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"Full\"):\n",
    "\tnetwork_architecture_Full = \\\n",
    "\t\tdict(n_hidden_recog_1=50, # 1st layer encoder neurons\n",
    "\t\t n_hidden_recog_2=50, # 2nd layer encoder neurons\n",
    "\t\t n_hidden_gener_1=50, # 1st layer decoder neurons\n",
    "\t\t n_hidden_gener_2=50, # 2nd layer decoder neurons\n",
    "\t\t n_input=200, # MNIST data input (img shape: 28*28)\n",
    "\t\t n_z=2)  # dimensionality of latent space\n",
    "\t#vae_Sem= VariationalAutoencoder(network_architecture_Sem,learning_rate=1e-4, batch_size=100)\n",
    "\tvae_Full=VariationalAutoencoder(network_architecture_Full,learning_rate=1e-4,batch_size=100)\n",
    "\n",
    "\n",
    "\n",
    "### Initialization\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session(config=config)\n",
    "sess.run(init)\n",
    "\n",
    "###Load  other models \n",
    "saver_depth.restore(sess,\"vae_models/depth_5_epochs/model\")\n",
    "print(\"loaded model weights from \"+\"models/depth_5_epochs/model\")\n",
    "\n",
    "saver_rgb.restore(sess,\"vae_models/RGB_1_epochs/model\")\n",
    "print(\"loaded model weights from \"+\"models/RGB_1_epochs/model\")\n",
    "\n",
    "saver_Sem.restore(sess,\"vae_models/sem_1_epochs/model\")\n",
    "print(\"loaded model weights from \"+\"models/sem_1_epochs/model\")\n",
    "\n",
    "\n",
    "###Build data for full model \n",
    "z_depth=sess.run(vae_depth.z_mean,feed_dict={vae_depth.x:Depth_input})\n",
    "z_rgb=sess.run(vae_rgb.z_mean,feed_dict={vae_rgb.x:RGB_input})\n",
    "z_sem=sess.run(vae_Sem.z_mean,feed_dict={vae_Sem.x:Sem_input})\n",
    "#z_in is the data required \n",
    "z_in=np.concatenate((z_rgb,z_depth,z_sem),axis=1)\n",
    "\n",
    "\n",
    "######################## variables list #########################\n",
    "listvar4=vae_Full.network_weights\n",
    "var_Full=(list(listvar4['weights_recog'].values())\n",
    "\t+list(listvar4['biases_recog'].values())\n",
    "\t+list(listvar4['weights_gener'].values())\n",
    "\t+list(listvar4['biases_gener'].values()))\n",
    "saver_Full=tf.train.Saver(var_Full)\n",
    "\n",
    "\n",
    "train_new_model=False\n",
    "if train_new_model:    \n",
    "\tvae_Full.train(batch_size=100, training_epochs=1)\n",
    "\tsaver_Full.save(sess,\"vae_models/full_1_epochs/model\")\n",
    "\tprint(\"saved the vae model weights to \"+\"models/full_1_epochs/model\")\n",
    "else:\n",
    "\tsaver_Full.restore(sess,\"vae_models/full_1_epochs/model\")\n",
    "\tprint(\"loaded the vae model weights from\"+\"models/full_1_epochs/model\")\n",
    "\n",
    "\tz_out=sess.run(vae_Full.x_reconstr_mean,feed_dict={vae_Full.x:z_in[0:100,:]})\n",
    "\tz_out_rgb,z_out_depth,z_out_sem=np.split(z_out, [50,100],axis=1)\n",
    "\trgb_out=sess.run(vae_rgb.x_reconstr_mean,feed_dict={vae_rgb.z:z_out_rgb})# shape [size,3240]\n",
    "\tdepth_image=sess.run(vae_depth.x_reconstr_mean,feed_dict={vae_depth.z:z_out_depth})# shape [size,1080]\n",
    "\tsem_out=sess.run(vae_Sem.x_reconstr_mean,feed_dict={vae_Sem.z:z_out_sem})# shape[size,5400]\n",
    "\n",
    "\tred_out,green_out,blue_out=np.split(rgb_out,3,axis=1)\n",
    "\tRGB_image=np.dstack((red_out,green_out,blue_out))\n",
    "\n",
    "\tG_out,O_out,V_out,B_out,S_out=np.split(sem_out,5,axis=1)\n",
    "\tSem_image=np.dstack((G_out,O_out,V_out,B_out,S_out))\n",
    "\tplt.imshow(np.reshape(depth_image[0],(18,60)))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
