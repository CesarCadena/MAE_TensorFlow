{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load fullMAE.py\n",
    "\n",
    "# %load autoencoder_tensorflow_MAE.py\n",
    "# Draft MAE Model in tensorflow based on Dr.Cesar Cadena\n",
    "# this code is developed by Yi Liu \n",
    "#run the code under the folder ~/project\n",
    "#this version has converged!\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from process_data import  process_data\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "batch_size=128\n",
    "num_epochs=200\n",
    "hidden_size=1024\n",
    "RESTORE=0\n",
    "\n",
    "\n",
    "#  prepare data \n",
    "data=process_data('training')\n",
    "Red_data=data['Red']\n",
    "Green_data=data['Green']\n",
    "Blue_data=data['Blue']\n",
    "Depth_data=data['Depth']\n",
    "Depthmask_data=data['Depthmask']\n",
    "Ground_data=data['Ground']\n",
    "Objects_data=data['Objects']\n",
    "Building_data=data['Building']\n",
    "Vegetation_data=data['Vegetation']\n",
    "Sky_data=data['Sky']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#load parameters\n",
    "pre_Depth_weights=np.load(\"../par/Depth_weights.npy\")\n",
    "pre_Depth_bias=np.load(\"../par/Depth_bias.npy\")\n",
    "pre_Depth_outweights=np.load(\"../par/Depth_outweights.npy\")\n",
    "pre_Depth_outbias=np.load(\"../par/Depth_outbias.npy\")\n",
    "\n",
    "pre_Red_weights=np.load(\"../par/Red_weights.npy\")\n",
    "pre_Red_bias=np.load(\"../par/Red_bias.npy\")\n",
    "pre_Red_outweights=np.load(\"../par/Red_outweights.npy\")\n",
    "pre_Red_outbias=np.load(\"../par/Red_outbias.npy\")\n",
    "\n",
    "pre_Green_weights=np.load(\"../par/Green_weights.npy\")\n",
    "pre_Green_bias=np.load(\"../par/Green_bias.npy\")\n",
    "pre_Green_outweights=np.load(\"../par/Green_outweights.npy\")\n",
    "pre_Green_outbias=np.load(\"../par/Green_outbias.npy\")\n",
    "\n",
    "pre_Blue_weights=np.load(\"../par/Blue_weights.npy\")\n",
    "pre_Blue_bias=np.load(\"../par/Blue_bias.npy\")\n",
    "pre_Blue_outweights=np.load(\"../par/Blue_outweights.npy\")\n",
    "pre_Blue_outbias=np.load(\"../par/Blue_outbias.npy\")\n",
    "\n",
    "pre_Ground_weights=np.load(\"../par/Ground_weights.npy\")\n",
    "pre_Ground_bias=np.load(\"../par/Ground_bias.npy\")\n",
    "pre_Ground_outweights=np.load(\"../par/Ground_outweights.npy\")\n",
    "pre_Ground_outbias=np.load(\"../par/Ground_outbias.npy\")\n",
    "\n",
    "pre_Objects_weights=np.load(\"../par/Objects_weights.npy\")\n",
    "pre_Objects_bias=np.load(\"../par/Objects_bias.npy\")\n",
    "pre_Objects_outweights=np.load(\"../par/Objects_outweights.npy\")\n",
    "pre_Objects_outbias=np.load(\"../par/Objects_outbias.npy\")\n",
    "\n",
    "pre_Building_weights=np.load(\"../par/Building_weights.npy\")\n",
    "pre_Building_bias=np.load(\"../par/Building_bias.npy\")\n",
    "pre_Building_outweights=np.load(\"../par/Building_outweights.npy\")\n",
    "pre_Building_outbias=np.load(\"../par/Building_outbias.npy\")\n",
    "\n",
    "pre_Vegetation_weights=np.load(\"../par/Vegetation_weights.npy\")\n",
    "pre_Vegetation_bias=np.load(\"../par/Vegetation_bias.npy\")\n",
    "pre_Vegetation_outweights=np.load(\"../par/Vegetation_outweights.npy\")\n",
    "pre_Vegetation_outbias=np.load(\"../par/Vegetation_outbias.npy\")\n",
    "\n",
    "pre_Sky_weights=np.load(\"../par/Sky_weights.npy\")\n",
    "pre_Sky_bias=np.load(\"../par/Sky_bias.npy\")\n",
    "pre_Sky_outweights=np.load(\"../par/Sky_outweights.npy\")\n",
    "pre_Sky_outbias=np.load(\"../par/Sky_outbias.npy\")\n",
    "\n",
    "\n",
    "pre_Semantic_weights=np.load(\"../par/Semantic_weights.npy\")\n",
    "pre_Semantic_bias=np.load(\"../par/Semantic_bias.npy\")\n",
    "pre_Semantic_deweights=np.load(\"../par/Semantic_deweights.npy\")\n",
    "pre_Semantic_debias=np.load(\"../par/Semantic_debias.npy\")\n",
    "# ##  full MAE\n",
    "\n",
    "\n",
    "\n",
    "### build full MAE  model \n",
    "# totally 9 channels (including mask channels)\n",
    "Red_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "Blue_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "Green_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "Depth_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "Depthmask_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "Ground_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "Objects_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "Building_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "Vegetation_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "Sky_input=tf.placeholder(tf.float32,shape=[None,1080])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Depth_weights=tf.Variable(pre_Depth_weights,name=\"Depth_weights\")\n",
    "Depth_bias=tf.Variable(pre_Depth_bias,name=\"Depth_bias\")\n",
    "\n",
    "\n",
    "Red_weights=tf.Variable(pre_Red_weights,name=\"Red_weights\")\n",
    "Red_bias=tf.Variable(pre_Red_bias,name=\"Red_bias\")\n",
    "\n",
    "\n",
    "Blue_weights=tf.Variable(pre_Blue_weights,name=\"Blue_weights\")\n",
    "Blue_bias=tf.Variable(pre_Blue_bias,name=\"Blue_bias\")\n",
    "\n",
    "\n",
    "Green_weights=tf.Variable(pre_Green_weights,name=\"Green_weights\")\n",
    "Green_bias=tf.Variable(pre_Green_bias,name=\"Green_bias\")\n",
    "\n",
    "\n",
    "Ground_weights=tf.Variable(pre_Ground_weights,name=\"Ground_weights\")\n",
    "Ground_bias=tf.Variable(pre_Ground_bias,name=\"Ground_bias\")\n",
    "\n",
    "\n",
    "Objects_weights=tf.Variable(pre_Objects_weights,name=\"Objects_weights\")\n",
    "Objects_bias=tf.Variable(pre_Objects_bias,name=\"Objects_bias\")\n",
    "\n",
    "\n",
    "Building_weights=tf.Variable(pre_Building_weights,name=\"Building_weights\")\n",
    "Building_bias=tf.Variable(pre_Building_bias,name=\"Building_bias\")\n",
    "\n",
    "\n",
    "Vegetation_weights=tf.Variable(pre_Vegetation_weights,name=\"Vegetation_weights\")\n",
    "Vegetation_bias=tf.Variable(pre_Vegetation_bias,name=\"Vegetation_bias\")\n",
    "\n",
    "\n",
    "Sky_weights=tf.Variable(pre_Sky_weights,name=\"Sky_weights\")\n",
    "Sky_bias=tf.Variable(pre_Sky_bias,name=\"Sky_bias\")\n",
    "\n",
    "\n",
    "Depth_hidden=tf.nn.relu(tf.matmul(Depth_input,Depth_weights)+Depth_bias)\n",
    "Red_hidden=tf.nn.relu(tf.matmul(Red_input,Red_weights)+Red_bias)\n",
    "Blue_hidden=tf.nn.relu(tf.matmul(Blue_input,Blue_weights)+Blue_bias)\n",
    "Green_hidden=tf.nn.relu(tf.matmul(Green_input,Green_weights)+Green_bias)\n",
    "Ground_hidden=tf.nn.relu(tf.matmul(Ground_input,Ground_weights)+Ground_bias)\n",
    "Objects_hidden=tf.nn.relu(tf.matmul(Objects_input,Objects_weights)+Objects_bias)\n",
    "Building_hidden=tf.nn.relu(tf.matmul(Building_input,Building_weights)+Building_bias)\n",
    "Vegetation_hidden=tf.nn.relu(tf.matmul(Vegetation_input,Vegetation_weights)+Vegetation_bias)\n",
    "Sky_hidden=tf.nn.relu(tf.matmul(Sky_input,Sky_weights)+Sky_bias)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Semantic_weights=tf.Variable(pre_Semantic_weights,name=\"Semantic_weights\")\n",
    "Semantic_bias=tf.Variable(pre_Semantic_bias,name=\"Semantic_bias\")\n",
    "\n",
    "Semantic_shared=tf.matmul(tf.concat([Ground_hidden,Objects_hidden,Building_hidden,Vegetation_hidden,Sky_hidden],1)\n",
    "                                     ,Semantic_weights)+Semantic_bias\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Fullshared_weights=tf.Variable(tf.random_normal(shape=[5*hidden_size,hidden_size],\n",
    "                               stddev=0.1),name=\"Fullshared_weights\")\n",
    "Fullshared_bias=tf.Variable(tf.zeros([1,hidden_size]),name=\"Fullshared_bias\")\n",
    "\n",
    "Full_shared=tf.matmul(tf.concat([Depth_hidden,Red_hidden,Green_hidden,Blue_hidden,\n",
    "                                            Semantic_shared],1),Fullshared_weights)+Fullshared_bias\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####decoder######\n",
    "\n",
    "Fullshared_deweights=tf.Variable(tf.random_normal(shape=[hidden_size,5*hidden_size],\n",
    "                           stddev=0.1),name=\"Fullshared_deweights\")\n",
    "Fullshared_debias=tf.Variable(tf.zeros([1,5*hidden_size]),name=\"Fullshared_debias\")\n",
    "\n",
    "decoder_layer=tf.matmul(Full_shared,Fullshared_deweights)+Fullshared_debias\n",
    "\n",
    "\n",
    "\n",
    "decoder_Depth,decoder_Red,decoder_Green,decoder_Blue,decoder_sem=tf.split(decoder_layer,num_or_size_splits=5, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "Semantic_deweights=tf.Variable(pre_Semantic_deweights,name=\"Semantic_deweights\")\n",
    "Semantic_debias=tf.Variable(pre_Semantic_debias,name=\"Semantic_debias\")\n",
    "decoder_sems=tf.matmul(decoder_sem,Semantic_deweights)+Semantic_debias\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decoder_Ground,decoder_Objects,decoder_Building,decoder_Vegetation,decoder_Sky=tf.split(decoder_sems,num_or_size_splits=5, axis=1)\n",
    "\n",
    "\n",
    "Depth_outweights=tf.Variable(pre_Depth_outweights,name=\"Depth_outweights\")\n",
    "Depth_outbias=tf.Variable(pre_Depth_outbias,name=\"Depth_outbias\")\n",
    "Depth_out=tf.matmul(decoder_Depth,Depth_outweights)+Depth_outbias\n",
    "\n",
    "\n",
    "Red_outweights=tf.Variable(pre_Red_outweights,name=\"Red_outweights\")\n",
    "Red_outbias=tf.Variable(pre_Red_outbias,name=\"Red_outbias\")\n",
    "Red_out=tf.nn.sigmoid(tf.matmul(decoder_Red,Red_outweights)+Red_outbias)\n",
    "\n",
    "Green_outweights=tf.Variable(pre_Green_outweights,name=\"Green_outweights\")\n",
    "Green_outbias=tf.Variable(pre_Green_outbias,name=\"Green_outbias\")\n",
    "Green_out=tf.nn.sigmoid(tf.matmul(decoder_Green,Green_outweights)+Green_outbias)\n",
    "\n",
    "Blue_outweights=tf.Variable(pre_Blue_outweights,name=\"Blue_outweights\")\n",
    "Blue_outbias=tf.Variable(pre_Blue_outbias,name=\"Blue_outbias\")\n",
    "Blue_out=tf.nn.sigmoid(tf.matmul(decoder_Blue,Blue_outweights)+Blue_outbias)\n",
    "\n",
    "\n",
    "Ground_outweights=tf.Variable(pre_Ground_outweights,name=\"ground_outweights\")\n",
    "Ground_outbias=tf.Variable(pre_Ground_outbias,name=\"ground_outbias\")\n",
    "Ground_out=tf.nn.sigmoid(tf.matmul(decoder_Ground,Ground_outweights)+Ground_outbias)\n",
    "\n",
    "Objects_outweights=tf.Variable(pre_Objects_outweights,name=\"Objects_outweights\")\n",
    "Objects_outbias=tf.Variable(pre_Objects_outbias,name=\"Objects_outbias\")\n",
    "Objects_out=tf.nn.sigmoid(tf.matmul(decoder_Objects,Objects_outweights)+Objects_outbias)\n",
    "\n",
    "\n",
    "Building_outweights=tf.Variable(pre_Building_outweights,name=\"Building_outweights\")\n",
    "Building_outbias=tf.Variable(pre_Building_outbias,name=\"Building_outbias\")\n",
    "Building_out=tf.nn.sigmoid(tf.matmul(decoder_Building,Building_outweights)+Building_outbias)\n",
    "\n",
    "\n",
    "Vegetation_outweights=tf.Variable(pre_Vegetation_outweights,name=\"Vegetation_outweights\")\n",
    "Vegetation_outbias=tf.Variable(pre_Vegetation_outbias,name=\"Vegetation_outbias\")\n",
    "Vegetation_out=tf.nn.sigmoid(tf.matmul(decoder_Vegetation,Vegetation_outweights)+Vegetation_outbias)\n",
    "\n",
    "Sky_outweights=tf.Variable(pre_Sky_outweights,name=\"Sky_outweights\")\n",
    "Sky_outbias=tf.Variable(pre_Sky_outbias,name=\"Sky_outbias\")\n",
    "Sky_out=tf.nn.sigmoid(tf.matmul(decoder_Sky,Sky_outweights)+Sky_outbias)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# be careful with this loss function\n",
    "\n",
    "loss=(tf.nn.l2_loss(Red_input-Red_out)\n",
    "     +tf.nn.l2_loss(Blue_input-Blue_out)\n",
    "     +tf.nn.l2_loss(Green_input-Green_out)\n",
    "     +5*tf.nn.l2_loss(np.multiply((Depth_input-Depth_out),Depthmask_input))\n",
    "     +tf.nn.l2_loss(Ground_input-Ground_out)\n",
    "     +tf.nn.l2_loss(Objects_input-Objects_out)\n",
    "     +tf.nn.l2_loss(Building_input-Building_out)\n",
    "     +tf.nn.l2_loss(Vegetation_input-Vegetation_out)\n",
    "     +tf.nn.l2_loss(Sky_input-Sky_out))\n",
    "\n",
    "\n",
    "\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=5e-04)\n",
    "regularization= tf.contrib.layers.apply_regularization(regularizer,\n",
    "                       weights_list=[Depth_weights,Red_weights,Blue_weights,\n",
    "                                     Green_weights,Ground_weights,Objects_weights,\n",
    "                                     Building_weights,Vegetation_weights,Sky_weights,\n",
    "                                     Semantic_weights,Fullshared_weights,Fullshared_deweights,\n",
    "                                     Depth_outweights,Red_outweights,Blue_outweights,\n",
    "                                     Green_outweights,Ground_outweights,Objects_outweights,\n",
    "                                     Building_outweights,Vegetation_outweights,Sky_outweights])\n",
    "\n",
    "        \n",
    "\n",
    "              \n",
    "loss_r=loss+regularization\n",
    "\n",
    "first_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                 \"Full\")\n",
    "\n",
    "optimizer_first=tf.train.AdamOptimizer(learning_rate=1e-3,beta1=0.9,beta2=0.999,\n",
    "                \n",
    "                                 epsilon=1e-3,use_locking=False,name='Adam').minimize(loss_r,var_list=first_train_vars)\n",
    "\n",
    "\n",
    "\n",
    "optimizer_second=tf.train.AdamOptimizer(learning_rate=1e-5,beta1=0.9,beta2=0.999,\n",
    "                                 epsilon=1e-3,use_locking=False,name='Adam').minimize(loss_r)\n",
    "\n",
    "\n",
    "####  training\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "init=tf.global_variables_initializer()\n",
    "train_size=Ground_data.shape[0]\n",
    "train_indices=range(train_size)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(truth,prediction):\n",
    "    #T=(np.where(truth>0) and np.where(prediction>0) )[0].astype(bool)\n",
    "    T1=truth>0\n",
    "    T2=prediction>0\n",
    "    T=np.logical_and(T1,T2)\n",
    "\n",
    "    #print (T)\n",
    "\n",
    "    truth=1/truth[T]\n",
    "    prediction=1/prediction[T]\n",
    "    \n",
    "    n=sum(T)\n",
    "    #print(n)\n",
    "  \n",
    "    error=sum((truth-prediction)**2)\n",
    "    rmse_error=np.sqrt(error/n)\n",
    "    \n",
    "    return rmse_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=process_data('validation')\n",
    "Red_data=data['Red']\n",
    "Green_data=data['Green']\n",
    "Blue_data=data['Blue']\n",
    "Depth_data=data['Depth']\n",
    "Depthmask_data=data['Depthmask']\n",
    "Ground_data=data['Ground']\n",
    "Objects_data=data['Objects']\n",
    "Building_data=data['Building']\n",
    "Vegetation_data=data['Vegetation']\n",
    "Sky_data=data['Sky']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depth_error import RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/MAE.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yi/anaconda/envs/ipykernel_py3/lib/python3.6/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,\"../model/MAE.ckpt\")\n",
    "    sumerror=0\n",
    "    l=Sky_data.shape[0]\n",
    "    for i in range(l):\n",
    "        \n",
    "        feed_dict={Sky_input:Sky_data[i:i+1,:],\n",
    "                   Objects_input:Objects_data[i:i+1,:],\n",
    "                   Building_input:Building_data[i:i+1,:],\n",
    "                   Vegetation_input:Vegetation_data[i:i+1,:],\n",
    "                   Ground_input:Ground_data[i:i+1,:],\n",
    "                   Red_input:Red_data[i:i+1,:],\n",
    "                   Green_input:Green_data[i:i+1,:],\n",
    "                   Blue_input:Blue_data[i:i+1,:],\n",
    "                   Depth_input:Depth_data[i:i+1,:],\n",
    "                   Depthmask_input:Depthmask_data[i:i+1,:]\n",
    "                  }\n",
    "        \n",
    "        outDepth_val=(np.reshape(sess.run(Green_out,feed_dict=feed_dict),(60,18)).transpose()*255).astype(np.uint8)\n",
    "        inDepth=(np.reshape(Green_data[i:i+1,:],(60,18)).transpose()*255).astype(np.uint8)\n",
    "           \n",
    "            \n",
    "        #fig,axes = plt.subplots(1,2)\n",
    "        #axes[0].imshow(outGround_val)\n",
    "        #axes[0].set_title('Green Channel Output')\n",
    "        \n",
    "        #axes[1].imshow(inGround)\n",
    "        #axes[1].set_title('Green Channel Input')\n",
    "        \n",
    "        #plt.savefig(\"../plot/val_%d.png\"%i)\n",
    "        \n",
    "        \n",
    "       # plt.figure(1)\n",
    "        #plt.imshow(outGround_val)\n",
    "        #plt.colorbar()\n",
    "        #plt.clim(-0.1,0.2)\n",
    "        \n",
    "        \n",
    "        #plt.figure(2)\n",
    "        #plt.imshow(inGround)\n",
    "        #plt.colorbar()\n",
    "        #plt.clim(-0.1,0.2)\n",
    "      \n",
    "        \n",
    "        \n",
    "        #plt.show()\n",
    "      \n",
    "        sumerror +=RMSE(Depth_data[i:i+1,:][0],sess.run(Depth_out,feed_dict=feed_dict)[0])\n",
    "    RMSE=sumerror/Sky_data.shape[0]\n",
    "        #print(RMSE(Depth_data[i:i+1,:][0],sess.run(Depth_out,feed_dict=feed_dict)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
