{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load VAE_full_test.py\n",
    "#This is VAE_depth script \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from depth_error import RMSE,ABSR\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.4\n",
    "tf.reset_default_graph()\n",
    "batch_size=1\n",
    "num_epochs=1\n",
    "depthpath=\"vae_models/depth_\"+str(num_epochs)+\"_epochs/model\"\n",
    "rgbpath=\"vae_models/rgb_\"+str(num_epochs)+\"_epochs/model\"\n",
    "sempath=\"vae_models/sem_\"+str(num_epochs)+\"_epochs/model\"\n",
    "fullpath=\"vae_models/full_\"+str(num_epochs)+\"_epochs/model\"\n",
    "\n",
    "\n",
    "\n",
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "\t\"\"\" Xavier initialization of network weights\"\"\"\n",
    "\t# https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "\tlow = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "\thigh = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "\t# return tensors\n",
    "\treturn tf.random_uniform((fan_in, fan_out), #  shape of the weights\n",
    "\t\t\t\t\t\t\t minval=low, maxval=high, # here is the range \n",
    "\t\t\t\t\t\t\t dtype=tf.float32) # here is the type\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(object):\n",
    "\t\"\"\" Based on See \"Auto-Encoding Variational Bayes\" by Kingma and Welling\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, network_architecture,\n",
    "\t\t\t\t transfer_fct=tf.nn.softplus,learning_rate=1e-3,batch_size=batch_size):\n",
    "\t\tself.network_architecture=network_architecture# which is a dictionary \n",
    "\t\tself.transfer_fct=transfer_fct\n",
    "\t\tself.learning_rate=learning_rate\n",
    "\t\tself.batch_size=batch_size\n",
    "\t\t# tf Graph input\n",
    "\t\tself.x=tf.placeholder(tf.float32,[None, network_architecture[\"n_input\"]])\n",
    "\t\t# Create auotencoder \n",
    "\t\tself.create_network()\n",
    "\t\t# define loss function based on variational upper bound \n",
    "\t\t# and corresponding optimizer \n",
    "\t\tself.create_loss_optimizer()\n",
    "\t\t#self.saver=tf.train.Saver()\n",
    "\n",
    "\n",
    "\tdef initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "\t\t\t\t\t\t\tn_hidden_gener_1,  n_hidden_gener_2, \n",
    "\t\t\t\t\t\t\tn_input, n_z):\n",
    "\t\t# create a dictionary of tensor variables \n",
    "\t\tall_weights = dict()\n",
    "\t\t# recognition  network\n",
    "\t\tall_weights['weights_recog'] = {\n",
    "\t\t\t'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "\t\t\t'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "\t\t\t'out_mean': tf.Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_2, n_z))}\n",
    "\t\tall_weights['biases_recog'] = {\n",
    "\t\t\t'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "\t\t\t'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "\t\t\t'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "\t\t# generate network \n",
    "\t\tall_weights['weights_gener'] = {\n",
    "\t\t\t'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "\t\t\t'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "\t\t\t'out_mean': tf.Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_2, n_input))}\n",
    "\t\tall_weights['biases_gener'] = {\n",
    "\t\t\t'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "\t\t\t'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "\t\t\t'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "\t\treturn all_weights\n",
    "\t\n",
    "\tdef create_network(self):\n",
    "\t\t# create tensor variables for  weights and bias\n",
    "\t\tself.network_weights=self.initialize_weights(**self.network_architecture) \n",
    "\t\t# network_weights  is a dictionary \n",
    "\t\t# pass architecture parameters \n",
    "\t\t# network_architecture is a dictionary \n",
    "\n",
    "\t\t# recognition network :\n",
    "\t\t#input: data x shape [batch_size,n_x]\n",
    "\t\t#output : mean of z , log(variance^2) shape [batch_size,n_z]\n",
    "\t\t# pass variables to network \n",
    "\t\tself.z_mean, self.z_log_sigma_sq = \\\n",
    "\t\t\tself.recognition_network(self.network_weights[\"weights_recog\"], \n",
    "\t\t\t\t\t\t\t\t\t self.network_weights[\"biases_recog\"])\n",
    "\t\t\t\n",
    "\t\tn_z = self.network_architecture[\"n_z\"]# dimension of z\n",
    "\t\t\n",
    "\t\t\n",
    "\t\teps = tf.random_normal((self.batch_size, n_z), 0, 1, dtype=tf.float32) \n",
    "\t\t# standard Normal\n",
    "\t\t# z = z_mean + z_sigma*epsilon\n",
    "\t\t\n",
    "\t\tself.z = tf.add(self.z_mean, tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n",
    "\t\t#shape [batch_size,n_z]\n",
    "\t\t\n",
    "\t\t# Generate network :\n",
    "\t\t# input z\n",
    "\t\t# output mean of pixels shape[batch_Size,n_x]\n",
    "\t\t# multivariant Gaussian Distribution\n",
    "\t\tself.x_reconstr_mean = \\\n",
    "\t\t\tself.generator_network(self.network_weights[\"weights_gener\"],\n",
    "\t\t\t\t\t\t\t\t   self.network_weights[\"biases_gener\"])\n",
    "\t\n",
    "\tdef recognition_network(self, weights, biases):\n",
    "\t\t# Generate probabilistic encoder (recognition network), which\n",
    "\t\t# maps inputs onto a normal distribution in latent space.\n",
    "\t\t# The transformation is parametrized and can be learned.\n",
    "\t\tlayer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b1'])) \n",
    "\t\tlayer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b2'])) \n",
    "\t\tz_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "\t\t\t\t\t\tbiases['out_mean'])\n",
    "\t\t\n",
    "\t\tz_log_sigma_sq =\\\n",
    "\t\t\ttf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "\t\t\t\t   biases['out_log_sigma'])\n",
    "\t\t\t\n",
    "\t\treturn (z_mean, z_log_sigma_sq)\n",
    "\t\n",
    "\t# use variables to buld generate network \n",
    "\tdef generator_network(self, weights, biases):\n",
    "\t\t# Generate probabilistic decoder (decoder network), which\n",
    "\t\t# maps points in latent space onto a Bernoulli distribution in data space.\n",
    "\t\t# The transformation is parametrized and can be learned.\n",
    "\t\tlayer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b1'])) \n",
    "\t\tlayer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b2'])) \n",
    "\t\t\n",
    "\t\t# depth estimation mean \n",
    "\t\tx_reconstr_mean = \\\n",
    "\t\t   tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "\t\t\t\t\t\t\t\t biases['out_mean'])\n",
    "\t\t#x_reconstr_sigma= \\\n",
    "\t\t#     tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "\t\t#                        biases['out_log_sigma'])\n",
    "\t\treturn x_reconstr_mean\n",
    "\t\n",
    "\tdef create_loss_optimizer(self):\n",
    "\t\t# The loss is composed of two terms:\n",
    "\t\t\n",
    "\t\t# 1.) The reconstruction loss (the negative log probability\n",
    "\t\t#     of the input under the reconstructed Bernoulli/Gaussian distribution \n",
    "\t\t#     induced by the decoder in the data space).\n",
    "\t\t#     This can be interpreted as the number of \"nats\" required\n",
    "\t\t#     for reconstructing the input when the activation in latent\n",
    "\t\t#     is given.\n",
    "\t\t# Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "\t\t# Assuem identity gaussian \n",
    "\t\t\n",
    "\t\t# loss from generative data \n",
    " \n",
    "\t\t# 1) bernouli distribution\n",
    "\t\t\"\"\"\n",
    "\t\treconstr_loss =-tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "\t\t\t\t\t\t   + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "\t\t\t\t\t\t   axis=1)\n",
    "\t\t\"\"\"\n",
    "\t\t# 1) gaussian distribution\n",
    "\t\treconstr_error=self.x-self.x_reconstr_mean\n",
    "\t\treconstr_loss=tf.reduce_sum(tf.square(reconstr_error),axis=1)\n",
    "\t\t# 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "\t\t##    between the distribution in latent space induced by the encoder on \n",
    "\t\t#     the data and some prior. This acts as a kind of regularizer.\n",
    "\t\t#     This can be interpreted as the number of \"nats\" required\n",
    "\t\t#     for transmitting the the latent space distribution given\n",
    "\t\t#     the prior.\n",
    "\t\t#     closed form of  KL  divergence with gaussian distribution\n",
    "\t\tlatent_loss=-0.5*tf.reduce_sum(1+self.z_log_sigma_sq \n",
    "\t\t\t\t\t\t\t\t\t\t   -tf.square(self.z_mean) \n",
    "\t\t\t\t\t\t\t\t\t\t   -tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "\t\tself.cost = tf.reduce_mean(reconstr_loss + latent_loss) # average over batch\n",
    "\t\t# Use ADAM optimizer\n",
    "\t\tself.optimizer = \\\n",
    "\t\t\ttf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\t\t\t\n",
    "\n",
    "\tdef partial_fit(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tTrain model based on mini-batch of input data.\n",
    "\t\tReturn cost of mini-batch.\n",
    "\t\t\"\"\"\n",
    "\t\topt,cost = sess.run((self.optimizer, self.cost), \n",
    "\t\t\t\t\t\t\t\t  feed_dict={self.x: X})\n",
    "\t\treturn cost\n",
    "\n",
    "\n",
    "#Build  network for depth channel\n",
    "with tf.variable_scope(\"depth\"):\n",
    "\tnetwork_architecture_depth= \\\n",
    "\t   dict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "\t\t n_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "\t\t n_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "\t\t n_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "\t\t n_input=1080, # MNIST data input (img shape: 28*28)\n",
    "\t\t n_z=50)  # dimensionality of latent space\n",
    "\tvae_depth=VariationalAutoencoder(network_architecture_depth,learning_rate=0.001,batch_size=batch_size)\n",
    "\n",
    "listvar=vae_depth.network_weights\n",
    "var_depth=(list(listvar['weights_recog'].values())\n",
    "\t+list(listvar['biases_recog'].values())\n",
    "\t+list(listvar['weights_gener'].values())\n",
    "\t+list(listvar['biases_gener'].values()))\n",
    "saver_depth=tf.train.Saver(var_depth)\n",
    "\n",
    "\n",
    "# Build network for semantics  channel\n",
    "with tf.variable_scope(\"RGB\"):\n",
    "\tnetwork_architecture_rgb= \\\n",
    "\t\tdict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "\t\t\tn_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "\t\t\tn_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "\t\t\tn_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "\t\t\tn_input=1080*3, # MNIST data input (img shape: 28*28)\n",
    "\t\t\tn_z=50)  # dimensionality of latent space\n",
    "\tvae_rgb=VariationalAutoencoder(network_architecture_rgb,learning_rate=0.001,batch_size=batch_size)\n",
    "  \n",
    "listvar2=vae_rgb.network_weights\n",
    "var_rgb=(list(listvar2['weights_recog'].values())\n",
    "\t+list(listvar2['biases_recog'].values())\n",
    "\t+list(listvar2['weights_gener'].values())\n",
    "\t+list(listvar2['biases_gener'].values()))\n",
    "saver_rgb=tf.train.Saver(var_rgb)\n",
    "\n",
    "\n",
    "# Build network for semantic channels\n",
    "with tf.variable_scope(\"Sem\"):\n",
    "\tnetwork_architecture_Sem = \\\n",
    "\t\tdict(n_hidden_recog_1=2000, # 1st layer encoder neurons\n",
    "\t\t n_hidden_recog_2=2000, # 2nd layer encoder neurons\n",
    "\t\t n_hidden_gener_1=2000, # 1st layer decoder neurons\n",
    "\t\t n_hidden_gener_2=2000, # 2nd layer decoder neurons\n",
    "\t\t n_input=5400, # MNIST data input (img shape: 28*28)\n",
    "\t\t n_z=100)  # dimensionality of latent space\n",
    "\tvae_Sem=VariationalAutoencoder(network_architecture_Sem,learning_rate=1e-4,batch_size=batch_size)\n",
    "\n",
    "listvar3=vae_Sem.network_weights\n",
    "var_Sem=(list(listvar3['weights_recog'].values())\n",
    "\t+list(listvar3['biases_recog'].values())\n",
    "\t+list(listvar3['weights_gener'].values())\n",
    "\t+list(listvar3['biases_gener'].values()))\n",
    "saver_Sem=tf.train.Saver(var_Sem)\n",
    "\n",
    "\n",
    "########################    Start build  shared information fusion   #############################\n",
    "with tf.variable_scope(\"Full\"):\n",
    "\tnetwork_architecture_Full = \\\n",
    "\t\tdict(n_hidden_recog_1=50, # 1st layer encoder neurons\n",
    "\t\t n_hidden_recog_2=50, # 2nd layer encoder neurons\n",
    "\t\t n_hidden_gener_1=50, # 1st layer decoder neurons\n",
    "\t\t n_hidden_gener_2=50, # 2nd layer decoder neurons\n",
    "\t\t n_input=200, # MNIST data input (img shape: 28*28)\n",
    "\t\t n_z=2)  # dimensionality of latent space\n",
    "\t#vae_Sem= VariationalAutoencoder(network_architecture_Sem,learning_rate=1e-4, batch_size=100)\n",
    "\tvae_Full=VariationalAutoencoder(network_architecture_Full,learning_rate=1e-4,batch_size=batch_size)\n",
    "\n",
    "listvar4=vae_Full.network_weights\n",
    "var_Full=(list(listvar4['weights_recog'].values())\n",
    "\t+list(listvar4['biases_recog'].values())\n",
    "\t+list(listvar4['weights_gener'].values())\n",
    "\t+list(listvar4['biases_gener'].values()))\n",
    "saver_Full=tf.train.Saver(var_Full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth_data=np.load(\"../Data_test/depth_data.npy\")\n",
    "depthmask_data=np.load(\"../Data_test/depthmask_data.npy\")\n",
    "Depth_input=depth_data[:,:,:,0].reshape(-1,1080)[0:37000]# shape [size,1080]\n",
    "Depthmask_input=depthmask_data[:,:,:,0].reshape(-1,1080)[0:37000]\n",
    "\n",
    "RGB_data=np.load(\"../Data_test/rgb_data.npy\")\n",
    "R_data=RGB_data[:,:,:,0].reshape(-1,1080)\n",
    "G_data=RGB_data[:,:,:,1].reshape(-1,1080)\n",
    "B_data=RGB_data[:,:,:,2].reshape(-1,1080)\n",
    "RGB_input=np.concatenate((R_data,G_data,B_data),axis=1)[0:37000] #shape[size,3*1080]\n",
    "\n",
    "Sem_data=np.load(\"../Data_test/sem_data.npy\")\n",
    "Ground_input=Sem_data[:,:,:,0].reshape(-1,1080)\n",
    "Objects_input=Sem_data[:,:,:,1].reshape(-1,1080)\n",
    "Building_input=Sem_data[:,:,:,2].reshape(-1,1080)\n",
    "Vegetation_input=Sem_data[:,:,:,3].reshape(-1,1080)\n",
    "Sky_input=Sem_data[:,:,:,4].reshape(-1,1080)\n",
    "Sem_input=np.concatenate((Ground_input,Objects_input,\n",
    "\t\t\t\t\t\t  Building_input,Vegetation_input,Sky_input),\n",
    "\t\t\t\t\t\t  axis=1)[0:37000]# shape[size,5*1080]\n",
    "print(Sem_input.shape)\n",
    "print(RGB_input.shape)\n",
    "print(Depth_input.shape)\n",
    "n_samples=Sem_input.shape[0] \n",
    "############################ Finish Load data ###################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vae_models/depth_1_epochs/model\n",
      "loaded model weights from vae_models/depth_1_epochs/model\n",
      "INFO:tensorflow:Restoring parameters from vae_models/rgb_1_epochs/model\n",
      "loaded model weights from vae_models/rgb_1_epochs/model\n",
      "INFO:tensorflow:Restoring parameters from vae_models/sem_1_epochs/model\n",
      "loaded model weights from vae_models/sem_1_epochs/model\n",
      "INFO:tensorflow:Restoring parameters from vae_models/full_1_epochs/model\n",
      "loaded the vae model weights fromvae_models/full_1_epochs/model\n",
      "(1, 100)\n",
      "(1, 50)\n",
      "(1, 50)\n",
      "(1, 200)\n",
      "Z1_in shape is  (1, 2)\n"
     ]
    }
   ],
   "source": [
    "### Initialization\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session(config=config)\n",
    "sess.run(init)\n",
    "###Load  other models \n",
    "saver_depth.restore(sess,depthpath)\n",
    "print(\"loaded model weights from \"+depthpath)\n",
    "saver_rgb.restore(sess,rgbpath)\n",
    "print(\"loaded model weights from \"+rgbpath)\n",
    "saver_Sem.restore(sess,sempath)\n",
    "print(\"loaded model weights from \"+sempath)\n",
    "######################## variables list #########################\n",
    "\n",
    "train_new_model=False\n",
    "if train_new_model:    \n",
    "\tvae_Full.train(batch_size=100, training_epochs=1)\n",
    "\tsaver_Full.save(sess,fullpath)\n",
    "\tprint(\"saved the vae model weights to \"+fullpath)\n",
    "else:\n",
    "\tsaver_Full.restore(sess,fullpath)\n",
    "\tprint(\"loaded the vae model weights from\"+fullpath)\n",
    "################################  make predictions  ##########################\n",
    "\n",
    "############################# Load test data ################################\n",
    "\n",
    "z1_depth=sess.run(vae_depth.z_mean,feed_dict={vae_depth.x:Depth_input[100:101]})\n",
    "z1_rgb=sess.run(vae_rgb.z_mean,feed_dict={vae_rgb.x:RGB_input[100:101]})\n",
    "z1_sem=sess.run(vae_Sem.z_mean,feed_dict={vae_Sem.x:Sem_input[100:101]})\n",
    "z1_in=np.concatenate((z1_rgb,z1_depth,z1_sem),axis=1)\n",
    "z1=sess.run(vae_Full.z,feed_dict={vae_Full.x:z1_in})\n",
    "\n",
    "z2_depth=sess.run(vae_depth.z_mean,feed_dict={vae_depth.x:Depth_input[100:101]*0})\n",
    "z2_rgb=sess.run(vae_rgb.z_mean,feed_dict={vae_rgb.x:RGB_input[100:101]})\n",
    "z2_sem=sess.run(vae_Sem.z_mean,feed_dict={vae_Sem.x:Sem_input[100:101]*0})\n",
    "z2_in=np.concatenate((z1_rgb,z1_depth,z1_sem),axis=1)\n",
    "z2=sess.run(vae_Full.z,feed_dict={vae_Full.x:z1_in})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37000, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAFpCAYAAADunkDIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x+RvZ/TUL8ibAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181a034b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6)) \n",
    "plt.scatter(z1[:,0], z1[:,1])#, c=np.argmax(y_sample, 1))\n",
    "#plt.colorbar()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
