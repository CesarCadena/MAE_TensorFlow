{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training started ...\n",
      "Epoch: 0001 cost= 32.941406987\n",
      "Epoch: 0002 cost= 32.553081551\n",
      "Epoch: 0003 cost= 32.429778038\n",
      "Epoch: 0004 cost= 32.350879815\n",
      "Epoch: 0005 cost= 32.270895279\n",
      "Epoch: 0006 cost= 32.237490576\n",
      "Epoch: 0007 cost= 32.199766290\n",
      "Epoch: 0008 cost= 32.189584338\n",
      "Epoch: 0009 cost= 32.166056667\n",
      "Epoch: 0010 cost= 32.162340067\n",
      "saved the vae model weights to vae_models/depth_1_epochs/model\n"
     ]
    }
   ],
   "source": [
    "# %load VAE_depth.py\n",
    "#This is VAE_depth script \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.4\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# Initialization Function\n",
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "    \"\"\" Xavier initialization of network weights\"\"\"\n",
    "    # https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "    # return tensors\n",
    "    return tf.random_uniform((fan_in, fan_out), #  shape of the weights\n",
    "                             minval=low, maxval=high, # here is the range \n",
    "                             dtype=tf.float32) # here is the type \n",
    "\n",
    "# Variational Auto Encoder \n",
    "class VariationalAutoencoder(object):\n",
    "    \n",
    "    \"\"\" Based on See \"Auto-Encoding Variational Bayes\" by Kingma and Welling\n",
    "    \"\"\"\n",
    "    def __init__(self, network_architecture,\n",
    "                 transfer_fct=tf.nn.relu,learning_rate=1e-3,batch_size=100):\n",
    "        \n",
    "        \n",
    "        self.network_architecture=network_architecture# which is a dictionary \n",
    "        self.transfer_fct=transfer_fct\n",
    "        self.learning_rate=learning_rate\n",
    "        self.batch_size=batch_size\n",
    "        # tf Graph input\n",
    "        self.x=tf.placeholder(tf.float32,[None, network_architecture[\"n_input\"]])\n",
    "        self.mask=tf.placeholder(tf.float32,[None, network_architecture[\"n_input\"]])\n",
    "        # Create auotencoder \n",
    "        self.create_network()\n",
    "        # define loss function based on variational upper bound \n",
    "        # and corresponding optimizer \n",
    "        self.create_loss_optimizer()\n",
    "        # initial the tensorflow variables \n",
    "        init=tf.global_variables_initializer()\n",
    "        self.saver_d=tf.train.Saver()\n",
    "        self.sess=tf.Session(config=config)\n",
    "        self.sess.run(init)\n",
    "    \n",
    "    \n",
    "            \n",
    "    def initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "                            n_hidden_gener_1,  n_hidden_gener_2, \n",
    "                            n_input, n_z):\n",
    "        \n",
    "        # create a dictionary of tensor variables \n",
    "        all_weights = dict()\n",
    "        # recognition  network\n",
    "        all_weights['weights_recog'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_2, n_z))}\n",
    "        all_weights['biases_recog'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "        \n",
    "        # generate network \n",
    "        all_weights['weights_gener'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_2, n_input))}\n",
    "        all_weights['biases_gener'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "        return all_weights\n",
    "    \n",
    "    def create_network(self):\n",
    "        # create tensor variables for  weights and bias\n",
    "        network_weights=self.initialize_weights(**self.network_architecture) \n",
    "        # pass architecture parameters \n",
    "        # network_architecture is a dictionary \n",
    "        \n",
    "        \n",
    "        # recognition network :\n",
    "        #input: data x shape [batch_size,n_x]\n",
    "        #output : mean of z , log(variance^2) shape [batch_size,n_z]\n",
    "        # pass variables to network \n",
    "        self.z_mean, self.z_log_sigma_sq = \\\n",
    "            self.recognition_network(network_weights[\"weights_recog\"], \n",
    "                                     network_weights[\"biases_recog\"])\n",
    "            \n",
    "        n_z = self.network_architecture[\"n_z\"]# dimension of z\n",
    "        \n",
    "        \n",
    "        eps = tf.random_normal((self.batch_size, n_z), 0, 1, dtype=tf.float32) \n",
    "        # standard Normal\n",
    "        # z = z_mean + z_sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n",
    "        #shape [batch_size,n_z]\n",
    "        \n",
    "        # Generate network :\n",
    "        # input z\n",
    "        # output mean of pixels shape[batch_Size,n_x]\n",
    "        # multivariant Gaussian Distribution\n",
    "        self.x_reconstr_mean = \\\n",
    "            self.generator_network(network_weights[\"weights_gener\"],\n",
    "                                   network_weights[\"biases_gener\"])\n",
    "    \n",
    "    def recognition_network(self, weights, biases):\n",
    "        # Generate probabilistic encoder (recognition network), which\n",
    "        # maps inputs onto a normal distribution in latent space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        z_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "                        biases['out_mean'])\n",
    "        \n",
    "        z_log_sigma_sq =\\\n",
    "            tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "                   biases['out_log_sigma'])\n",
    "            \n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "    \n",
    "    # use variables to buld generate network \n",
    "    def generator_network(self, weights, biases):\n",
    "        # Generate probabilistic decoder (decoder network), which\n",
    "        # maps points in latent space onto a Bernoulli distribution in data space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        \n",
    "        # depth estimation mean \n",
    "        x_reconstr_mean = \\\n",
    "           tf.nn.relu(tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "                                 biases['out_mean']))\n",
    "            \n",
    "        #x_reconstr_sigma= \\\n",
    "        #     tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "        #                        biases['out_log_sigma'])\n",
    "            \n",
    "        return x_reconstr_mean\n",
    "    \n",
    "    def create_loss_optimizer(self):\n",
    "        # The loss is composed of two terms:\n",
    "        \n",
    "        # 1.) The reconstruction loss (the negative log probability\n",
    "        #     of the input under the reconstructed Bernoulli/Gaussian distribution \n",
    "        #     induced by the decoder in the data space).\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for reconstructing the input when the activation in latent\n",
    "        #     is given.\n",
    "        # Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "        # Assuem identity gaussian \n",
    "        \n",
    "        # loss from generative data \n",
    "        \n",
    "        # 1) bernouli distribution\n",
    "        \"\"\"\n",
    "        reconstr_loss =-tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "                           axis=1)\n",
    "        \"\"\"\n",
    "        # 1) gaussian distribution\n",
    "        reconstr_error=(self.x-self.x_reconstr_mean)*self.mask\n",
    "        reconstr_loss=tf.reduce_sum(tf.square(reconstr_error),axis=1)\n",
    "          \n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        #     closed form of  KL  divergence with gaussian distribution\n",
    "        latent_loss=-0.5*tf.reduce_sum(1+self.z_log_sigma_sq \n",
    "                                           -tf.square(self.z_mean) \n",
    "                                           -tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        \n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss) # average over batch\n",
    "        # Use ADAM optimizer\n",
    "        \n",
    "        self.optimizer = \\\n",
    "            tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "    def partial_fit(self, X):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x: X})\n",
    "        return cost\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})\n",
    "    \n",
    "    def save(self, check_point_file = 'model.ckpt'):\n",
    "        save_path = self.saver_d.save(self.sess, check_point_file) # Saves the weights (not the graph)\n",
    "        print(\"saved the vae model weights to \"+save_path)\n",
    "        # to load it,\n",
    "        \n",
    "    def load(self, check_point_file = 'model.ckpt'):\n",
    "        self.saver_d.restore(self.sess, check_point_file)\n",
    "        print(\"loaded model weights from \"+check_point_file)\n",
    "        \n",
    "    def train(self, batch_size=100,training_epochs=1,display_step=1):\n",
    "        print(\"training started ...\")\n",
    "        train_indices=range(n_samples)\n",
    "        \n",
    "        for epoch in range(training_epochs):\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(n_samples / batch_size)\n",
    "            perm_indices=np.random.permutation(train_indices)\n",
    "        # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "                \n",
    "                offset=(i*batch_size)%(n_samples-batch_size)\n",
    "                # mnist data  batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "                batch_indices=perm_indices[offset:(offset+batch_size)]\n",
    "                \n",
    "                batch_xs=Depth_input[batch_indices]\n",
    "                batch_mask=Depthmask_input[batch_indices]\n",
    "            # Fit training using batch data\n",
    "                _,cost=self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x:batch_xs,self.mask:batch_mask})\n",
    "              \n",
    "            # Compute average loss\n",
    "                avg_cost += cost / n_samples * batch_size\n",
    "        # Display logs per epoch step\n",
    "            if epoch % display_step == 0:\n",
    "                print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                      \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "\n",
    "# Load depth data \n",
    "depth_data=np.load(\"../Data/depth_data.npy\")\n",
    "depthmask_data=np.load(\"../Data/depth_mask.npy\")\n",
    "Depth_input=depth_data[:,:,:,0].reshape(-1,1080)\n",
    "Depthmask_input=depthmask_data[:,:,:,0].reshape(-1,1080)\n",
    "#Depth_input=np.transpose(depth_data,(0,2,1,3))[:,:,:,0].reshape(-1,1080)\n",
    "n_samples=Depth_input.shape[0]\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"depth\"):\n",
    "    network_architecture = \\\n",
    "        dict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "         n_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "         n_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "         n_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "         n_input=1080, # MNIST data input (img shape: 28*28)\n",
    "         n_z=50)  # dimensionality of latent space\n",
    "    vae = VariationalAutoencoder(network_architecture,learning_rate=1e-3,batch_size=100)\n",
    "\n",
    "\n",
    "train_new_model =True\n",
    "if train_new_model:    \n",
    "    vae.train(batch_size=100,training_epochs=10)\n",
    "    vae.save(\"vae_models/depth_1_epochs/model\")\n",
    "else:\n",
    "    vae.load(\"vae_models/depth_1_epochs/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        ,  0.05544548,  0.05381951, ...,  0.18291567,\n",
       "        0.18345258,  0.17574692])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Depth_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "prediction=vae.sess.run(vae.x_reconstr_mean,feed_dict={vae.x:Depth_input[0:1,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.1843422 , 0.18180323,\n",
       "       0.1825929 ], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181cba47b8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACHCAYAAAAGEqJQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxadhWcY3TfDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181d8383c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Depth_input[0].reshape(18,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181ad1cc18>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACHCAYAAAAGEqJQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAV0EZFEKKCLiCRCAV1EJBH/DTM0B7ZHu1zlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181d808dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(prediction[0].reshape(18,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
