{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30602, 18, 60, 1)\n",
      "(30602, 18, 60, 5)\n",
      "(30602, 18, 60, 3)\n",
      "INFO:tensorflow:Restoring parameters from CNN_full/cnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "# %load CNN_full_test.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from process_data import  process_data\n",
    "batch_size=20\n",
    "num_epochs=100\n",
    "hidden_size=1024\n",
    "RESTORE=0\n",
    "SEED = None\n",
    "\n",
    "#  load data \n",
    "data_depth=np.load('../depth_data.npy')\n",
    "data_depth=np.transpose(data_depth,(0,2,1,3))# swap the two dimensions\n",
    "print(data_depth.shape)\n",
    "\n",
    "data_sem=np.load('../sem_data.npy')\n",
    "data_sem=np.transpose(data_sem,(0,2,1,3))# swap the two dimensions\n",
    "print(data_sem.shape)\n",
    "\n",
    "data_rgb=np.load('../rgb_data.npy')\n",
    "data_rgb=np.transpose(data_rgb,(0,2,1,3))# swap the two dimensions\n",
    "print(data_rgb.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Encoder\n",
    "\n",
    "inputs_depth= tf.placeholder(tf.float32,(None, 18,60,1), name=\"input_depth\")\n",
    "outputs_depth=tf.placeholder(tf.float32,(None, 18,60,1), name=\"ouput_depth\")\n",
    "\n",
    "inputs_sem= tf.placeholder(tf.float32,(None, 18,60,5), name=\"input_sem\")\n",
    "outputs_sem=tf.placeholder(tf.float32,(None, 18,60,5), name=\"ouput_sem\")\n",
    "\n",
    "inputs_rgb=tf.placeholder(tf.float32,(None, 18,60,3), name=\"input_rgb\")\n",
    "outputs_rgb=tf.placeholder(tf.float32,(None, 18,60,3), name=\"ouput_rgb\")\n",
    "\n",
    "############################## Depth #############################\n",
    "conv1_depth=tf.layers.conv2d(inputs=inputs_depth,filters=16,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "#now (batch,18,60,16)\n",
    "\n",
    "pool1_depth=tf.layers.max_pooling2d(conv1_depth,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "#now (batch,9,30,16)\n",
    "\n",
    "conv2_depth=tf.layers.conv2d(inputs=pool1_depth,filters=8,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "# now (batch,9,30,8)\n",
    "\n",
    "pool2_depth=tf.layers.max_pooling2d(conv2_depth,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "#now (batch,5,15,8)\n",
    "\n",
    "################################## Semantic #################################################\n",
    "\n",
    "conv1_sem=tf.layers.conv2d(inputs=inputs_sem,filters=16,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "#now (batch,18,60,16)\n",
    "\n",
    "pool1_sem=tf.layers.max_pooling2d(conv1_sem,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "#now (batch,9,30,16)\n",
    "\n",
    "conv2_sem=tf.layers.conv2d(inputs=pool1_sem,filters=8,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "# now (batch,9,30,8)\n",
    "\n",
    "pool2_sem=tf.layers.max_pooling2d(conv2_sem,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "#now (batch,5,15,8)\n",
    "####################################  RGB  ###############################################\n",
    "conv1_rgb=tf.layers.conv2d(inputs=inputs_rgb,filters=16,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "#now (batch,18,60,16)\n",
    "\n",
    "pool1_rgb=tf.layers.max_pooling2d(conv1_rgb,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "#now (batch,9,30,16)\n",
    "\n",
    "conv2_rgb=tf.layers.conv2d(inputs=pool1_rgb,filters=8,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "# now (batch,9,30,8)\n",
    "\n",
    "pool2_rgb=tf.layers.max_pooling2d(conv2_rgb,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "#now (batch,5,15,8)\n",
    "\n",
    "\n",
    "\n",
    "####Modalities Fusion\n",
    "\n",
    "flat_hidden_sem=tf.reshape(pool2_sem,[-1,600])\n",
    "flat_hidden_depth=tf.reshape(pool2_depth,[-1,600])\n",
    "flat_hidden_rgb=tf.reshape(pool2_rgb,[-1,600])\n",
    "########## Define Parameters #########\n",
    "weights_in=tf.Variable(tf.random_normal(shape=[1800,1024],\n",
    "                                   stddev=0.01),name=\"weights_in\")\n",
    "bias_in=tf.Variable(tf.zeros([1,1024]),name=\"bias_in\")\n",
    "\n",
    "# full shared units\n",
    "flat_full=tf.concat([flat_hidden_rgb,flat_hidden_depth,flat_hidden_sem],axis=1)\n",
    "full_hidden=tf.nn.relu(tf.matmul(flat_full,weights_in)+bias_in)\n",
    "\n",
    "weights_out=tf.Variable(tf.random_normal(shape=[1024,1800],\n",
    "                                   stddev=0.01),name=\"weights_in\")\n",
    "bias_out=tf.Variable(tf.zeros([1,1800]),name=\"bias_in\")\n",
    "\n",
    "flat_full_out=tf.nn.relu(tf.matmul(full_hidden,weights_out)+bias_out)\n",
    "\n",
    "\n",
    "hidden_rgb_out,hidden_depth_out,hidden_sem_out=tf.split(flat_full_out,num_or_size_splits=3,axis=1)\n",
    "\n",
    "\n",
    "pool2_depth_out=tf.reshape(hidden_depth_out,[-1,5,15,8])\n",
    "pool2_sem_out=tf.reshape(hidden_sem_out,[-1,5,15,8])\n",
    "pool2_rgb_out=tf.reshape(hidden_rgb_out,[-1,5,15,8])\n",
    "\n",
    "##Decoder\n",
    "\n",
    "### Decoder using high level modules \n",
    "upsample1_depth=tf.image.resize_images(pool2_depth_out,size=(9,30),\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# now (batch,9,30,8)\n",
    "conv4_depth=tf.layers.conv2d(inputs=upsample1_depth,filters=16,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "#now (batch,9,30,8)\n",
    "\n",
    "upsample2_depth= tf.image.resize_images(conv4_depth, size=(18,60),\n",
    "                                   method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "#now (batch,18,60,8)\n",
    "out_depth=tf.layers.conv2d(inputs=upsample2_depth,filters=1,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "\n",
    "################################################\n",
    "\n",
    "upsample1_sem=tf.image.resize_images(pool2_sem_out,size=(9,30),\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# now (batch,9,30,8)\n",
    "conv4_sem=tf.layers.conv2d(inputs=upsample1_sem,filters=16,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "#now (batch,9,30,8)\n",
    "\n",
    "upsample2_sem= tf.image.resize_images(conv4_sem, size=(18,60),\n",
    "                                   method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "#now (batch,18,60,8)\n",
    "out_sem=tf.layers.conv2d(inputs=upsample2_sem,filters=5,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "##################################################\n",
    "\n",
    "\n",
    "upsample1_rgb=tf.image.resize_images(pool2_rgb_out,size=(9,30),\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "# now (batch,9,30,8)\n",
    "conv4_rgb=tf.layers.conv2d(inputs=upsample1_rgb,filters=16,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "#now (batch,9,30,8)\n",
    "\n",
    "upsample2_rgb= tf.image.resize_images(conv4_rgb, size=(18,60),\n",
    "                                   method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "#now (batch,18,60,8)\n",
    "out_rgb=tf.layers.conv2d(inputs=upsample2_rgb,filters=3,kernel_size=(3,3),padding='same',\n",
    "                       activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "# define loss\n",
    "learning_rate=1e-4\n",
    "loss=(tf.nn.l2_loss(out_rgb-outputs_rgb)\n",
    "     +tf.nn.l2_loss(out_sem-outputs_sem)\n",
    "     +tf.nn.l2_loss(out_depth-outputs_depth)\n",
    "     )\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "train_size=data_depth.shape[0]\n",
    "train_indices=range(train_size)   \n",
    "\n",
    "CNN_path=\"../CNN_full\"\n",
    "if not os.path.isdir(CNN_path):\n",
    "    os.mkdir(CNN_path)          \n",
    "saver=tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'CNN_full/cnn.ckpt')\n",
    "    l=sess.run(out_sem,feed_dict={inputs_depth:data_depth[0:1],\n",
    "                                                     outputs_depth:data_depth[0:1],\n",
    "                                                     inputs_rgb:data_rgb[0:1],\n",
    "                                                     outputs_rgb:data_rgb[0:1],\n",
    "                                                     inputs_sem:data_sem[0:1],\n",
    "                                                     outputs_sem:data_sem[0:1]\n",
    "                                                    })     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruction=np.argmax(l,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18, 60)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  output reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1acfec2b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACHCAYAAAAGEqJQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUQVLewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b260630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reconstruction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image=np.argmax(data_sem[0:1],axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b2606a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACHCAYAAAAGEqJQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJAEgQ4ASRDoAJDE/wBcoyNGL0TlJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b41b74e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
