{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load VAE_full.py\n",
    "#This is VAE_depth script \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.4\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "\t\"\"\" Xavier initialization of network weights\"\"\"\n",
    "\t# https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "\tlow = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "\thigh = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "\t# return tensors\n",
    "\treturn tf.random_uniform((fan_in, fan_out), #  shape of the weights\n",
    "\t\t\t\t\t\t\t minval=low, maxval=high, # here is the range \n",
    "\t\t\t\t\t\t\t dtype=tf.float32) # here is the type\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(object):\n",
    "\t\"\"\" Based on See \"Auto-Encoding Variational Bayes\" by Kingma and Welling\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, network_architecture,\n",
    "\t\t\t\t transfer_fct=tf.nn.softplus,learning_rate=1e-3,batch_size=100):\n",
    "\t\tself.network_architecture=network_architecture# which is a dictionary \n",
    "\t\tself.transfer_fct=transfer_fct\n",
    "\t\tself.learning_rate=learning_rate\n",
    "\t\tself.batch_size=batch_size\n",
    "\t\t# tf Graph input\n",
    "\t\tself.x=tf.placeholder(tf.float32,[None, network_architecture[\"n_input\"]])\n",
    "\t\t# Create auotencoder \n",
    "\t\tself.create_network()\n",
    "\t\t# define loss function based on variational upper bound \n",
    "\t\t# and corresponding optimizer \n",
    "\t\tself.create_loss_optimizer()\n",
    "\t\t#self.saver=tf.train.Saver()\n",
    "\n",
    "\n",
    "\tdef initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "\t\t\t\t\t\t\tn_hidden_gener_1,  n_hidden_gener_2, \n",
    "\t\t\t\t\t\t\tn_input, n_z):\n",
    "\t\t# create a dictionary of tensor variables \n",
    "\t\tall_weights = dict()\n",
    "\t\t# recognition  network\n",
    "\t\tall_weights['weights_recog'] = {\n",
    "\t\t\t'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "\t\t\t'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "\t\t\t'out_mean': tf.Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_2, n_z))}\n",
    "\t\tall_weights['biases_recog'] = {\n",
    "\t\t\t'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "\t\t\t'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "\t\t\t'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "\t\t# generate network \n",
    "\t\tall_weights['weights_gener'] = {\n",
    "\t\t\t'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "\t\t\t'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "\t\t\t'out_mean': tf.Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_2, n_input))}\n",
    "\t\tall_weights['biases_gener'] = {\n",
    "\t\t\t'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "\t\t\t'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "\t\t\t'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "\t\t\t'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "\t\treturn all_weights\n",
    "\t\n",
    "\tdef create_network(self):\n",
    "\t\t# create tensor variables for  weights and bias\n",
    "\t\tself.network_weights=self.initialize_weights(**self.network_architecture) \n",
    "\t\t# network_weights  is a dictionary \n",
    "\t\t# pass architecture parameters \n",
    "\t\t# network_architecture is a dictionary \n",
    "\n",
    "\t\t# recognition network :\n",
    "\t\t#input: data x shape [batch_size,n_x]\n",
    "\t\t#output : mean of z , log(variance^2) shape [batch_size,n_z]\n",
    "\t\t# pass variables to network \n",
    "\t\tself.z_mean, self.z_log_sigma_sq = \\\n",
    "\t\t\tself.recognition_network(self.network_weights[\"weights_recog\"], \n",
    "\t\t\t\t\t\t\t\t\t self.network_weights[\"biases_recog\"])\n",
    "\t\t\t\n",
    "\t\tn_z = self.network_architecture[\"n_z\"]# dimension of z\n",
    "\t\t\n",
    "\t\t\n",
    "\t\teps = tf.random_normal((self.batch_size, n_z), 0, 1, dtype=tf.float32) \n",
    "\t\t# standard Normal\n",
    "\t\t# z = z_mean + z_sigma*epsilon\n",
    "\t\t\n",
    "\t\tself.z = tf.add(self.z_mean, tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n",
    "\t\t#shape [batch_size,n_z]\n",
    "\t\t\n",
    "\t\t# Generate network :\n",
    "\t\t# input z\n",
    "\t\t# output mean of pixels shape[batch_Size,n_x]\n",
    "\t\t# multivariant Gaussian Distribution\n",
    "\t\tself.x_reconstr_mean = \\\n",
    "\t\t\tself.generator_network(self.network_weights[\"weights_gener\"],\n",
    "\t\t\t\t\t\t\t\t   self.network_weights[\"biases_gener\"])\n",
    "\t\n",
    "\tdef recognition_network(self, weights, biases):\n",
    "\t\t# Generate probabilistic encoder (recognition network), which\n",
    "\t\t# maps inputs onto a normal distribution in latent space.\n",
    "\t\t# The transformation is parametrized and can be learned.\n",
    "\t\tlayer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b1'])) \n",
    "\t\tlayer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b2'])) \n",
    "\t\tz_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "\t\t\t\t\t\tbiases['out_mean'])\n",
    "\t\t\n",
    "\t\tz_log_sigma_sq =\\\n",
    "\t\t\ttf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "\t\t\t\t   biases['out_log_sigma'])\n",
    "\t\t\t\n",
    "\t\treturn (z_mean, z_log_sigma_sq)\n",
    "\t\n",
    "\t# use variables to buld generate network \n",
    "\tdef generator_network(self, weights, biases):\n",
    "\t\t# Generate probabilistic decoder (decoder network), which\n",
    "\t\t# maps points in latent space onto a Bernoulli distribution in data space.\n",
    "\t\t# The transformation is parametrized and can be learned.\n",
    "\t\tlayer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b1'])) \n",
    "\t\tlayer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "\t\t\t\t\t\t\t\t\t\t   biases['b2'])) \n",
    "\t\t\n",
    "\t\t# depth estimation mean \n",
    "\t\tx_reconstr_mean = \\\n",
    "\t\t   tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "\t\t\t\t\t\t\t\t biases['out_mean'])\n",
    "\t\t#x_reconstr_sigma= \\\n",
    "\t\t#     tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "\t\t#                        biases['out_log_sigma'])\n",
    "\t\treturn x_reconstr_mean\n",
    "\t\n",
    "\tdef create_loss_optimizer(self):\n",
    "\t\t# The loss is composed of two terms:\n",
    "\t\t\n",
    "\t\t# 1.) The reconstruction loss (the negative log probability\n",
    "\t\t#     of the input under the reconstructed Bernoulli/Gaussian distribution \n",
    "\t\t#     induced by the decoder in the data space).\n",
    "\t\t#     This can be interpreted as the number of \"nats\" required\n",
    "\t\t#     for reconstructing the input when the activation in latent\n",
    "\t\t#     is given.\n",
    "\t\t# Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "\t\t# Assuem identity gaussian \n",
    "\t\t\n",
    "\t\t# loss from generative data \n",
    " \n",
    "\t\t# 1) bernouli distribution\n",
    "\t\t\"\"\"\n",
    "\t\treconstr_loss =-tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "\t\t\t\t\t\t   + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "\t\t\t\t\t\t   axis=1)\n",
    "\t\t\"\"\"\n",
    "\t\t# 1) gaussian distribution\n",
    "\t\treconstr_error=self.x-self.x_reconstr_mean\n",
    "\t\treconstr_loss=tf.reduce_sum(tf.square(reconstr_error),axis=1)\n",
    "\t\t# 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "\t\t##    between the distribution in latent space induced by the encoder on \n",
    "\t\t#     the data and some prior. This acts as a kind of regularizer.\n",
    "\t\t#     This can be interpreted as the number of \"nats\" required\n",
    "\t\t#     for transmitting the the latent space distribution given\n",
    "\t\t#     the prior.\n",
    "\t\t#     closed form of  KL  divergence with gaussian distribution\n",
    "\t\tlatent_loss=-0.5*tf.reduce_sum(1+self.z_log_sigma_sq \n",
    "\t\t\t\t\t\t\t\t\t\t   -tf.square(self.z_mean) \n",
    "\t\t\t\t\t\t\t\t\t\t   -tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "\t\tself.cost = tf.reduce_mean(reconstr_loss + latent_loss) # average over batch\n",
    "\t\t# Use ADAM optimizer\n",
    "\t\tself.optimizer = \\\n",
    "\t\t\ttf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\t\t\t\n",
    "\n",
    "\tdef partial_fit(self, X):\n",
    "\t\t\"\"\"\n",
    "\t\tTrain model based on mini-batch of input data.\n",
    "\t\tReturn cost of mini-batch.\n",
    "\t\t\"\"\"\n",
    "\t\topt,cost = sess.run((self.optimizer, self.cost), \n",
    "\t\t\t\t\t\t\t\t  feed_dict={self.x: X})\n",
    "\t\treturn cost\n",
    "\n",
    "\n",
    "\tdef train(self, batch_size=100, training_epochs=10, display_step=1):\n",
    "\t\tprint(\"training started ...\")\n",
    "\t\ttrain_indices=range(n_samples)\n",
    "\t\tfor epoch in range(training_epochs):\n",
    "\t\t\tavg_cost = 0.\n",
    "\t\t\ttotal_batch = int(n_samples / batch_size)\n",
    "\t\t\tperm_indices=np.random.permutation(train_indices)\n",
    "\t\t# Loop over all batches\n",
    "\t\t\tfor i in range(total_batch):\n",
    "\t\t\t\toffset=(i*batch_size)%(n_samples-batch_size)\n",
    "\t\t\t\t# mnist data  batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "\t\t\t\tbatch_indices=perm_indices[offset:(offset+batch_size)]\n",
    "\t\t\t\t# feed the data for full models \n",
    "\t\t\t\tbatch_xs=z_in[batch_indices]\n",
    "\t\t\t# Fit training using batch data\n",
    "\t\t\t\tcost = self.partial_fit(batch_xs)\n",
    "\t\t\t# Compute average loss\n",
    "\t\t\t\tavg_cost += cost/n_samples*batch_size\n",
    "\t\t# Display logs per epoch step\n",
    "\t\t\tif epoch % display_step == 0:\n",
    "\t\t\t\tprint(\"Epoch:\", '%04d' % (epoch+1), \n",
    "\t\t\t\t\t  \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Build  network for depth channel\n",
    "with tf.variable_scope(\"depth\"):\n",
    "\tnetwork_architecture_depth= \\\n",
    "\t   dict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "\t\t n_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "\t\t n_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "\t\t n_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "\t\t n_input=1080, # MNIST data input (img shape: 28*28)\n",
    "\t\t n_z=50)  # dimensionality of latent space\n",
    "\tvae_depth=VariationalAutoencoder(network_architecture_depth,learning_rate=0.001,batch_size=100)\n",
    "\n",
    "listvar=vae_depth.network_weights\n",
    "var_depth=(list(listvar['weights_recog'].values())\n",
    "\t+list(listvar['biases_recog'].values())\n",
    "\t+list(listvar['weights_gener'].values())\n",
    "\t+list(listvar['biases_gener'].values()))\n",
    "saver_depth=tf.train.Saver(var_depth)\n",
    "\n",
    "\n",
    "# Build network for semantics  channel\n",
    "with tf.variable_scope(\"RGB\"):\n",
    "\tnetwork_architecture_rgb= \\\n",
    "\t\tdict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "\t\t\tn_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "\t\t\tn_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "\t\t\tn_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "\t\t\tn_input=1080*3, # MNIST data input (img shape: 28*28)\n",
    "\t\t\tn_z=50)  # dimensionality of latent space\n",
    "\tvae_rgb=VariationalAutoencoder(network_architecture_rgb,learning_rate=0.001,batch_size=100)\n",
    "    \n",
    "listvar2=vae_rgb.network_weights\n",
    "var_rgb=(list(listvar2['weights_recog'].values())\n",
    "\t+list(listvar2['biases_recog'].values())\n",
    "\t+list(listvar2['weights_gener'].values())\n",
    "\t+list(listvar2['biases_gener'].values()))\n",
    "saver_rgb=tf.train.Saver(var_rgb)\n",
    "\n",
    "\n",
    "# Build network for semantic channels\n",
    "with tf.variable_scope(\"Sem\"):\n",
    "\tnetwork_architecture_Sem = \\\n",
    "\t\tdict(n_hidden_recog_1=2000, # 1st layer encoder neurons\n",
    "\t\t n_hidden_recog_2=2000, # 2nd layer encoder neurons\n",
    "\t\t n_hidden_gener_1=2000, # 1st layer decoder neurons\n",
    "\t\t n_hidden_gener_2=2000, # 2nd layer decoder neurons\n",
    "\t\t n_input=5400, # MNIST data input (img shape: 28*28)\n",
    "\t\t n_z=100)  # dimensionality of latent space\n",
    "\tvae_Sem=VariationalAutoencoder(network_architecture_Sem,learning_rate=1e-4,batch_size=100)\n",
    "\n",
    "listvar3=vae_Sem.network_weights\n",
    "var_Sem=(list(listvar3['weights_recog'].values())\n",
    "\t+list(listvar3['biases_recog'].values())\n",
    "\t+list(listvar3['weights_gener'].values())\n",
    "\t+list(listvar3['biases_gener'].values()))\n",
    "saver_Sem=tf.train.Saver(var_Sem)\n",
    "\n",
    "\n",
    "########################    Start build  shared information fusion   #############################\n",
    "\n",
    "\n",
    "\n",
    "########################    Start build  shared information fusion   #############################\n",
    "############## Load data ####################\n",
    "depth_data=np.load(\"../Data/depth_data.npy\")\n",
    "Depth_input=np.transpose(depth_data,(0,2,1,3))[:,:,:,0].reshape(-1,1080)# shape [size,1080]\n",
    "\n",
    "RGB_data=np.load(\"../Data/rgb_data.npy\")\n",
    "R_data=RGB_data[:,:,:,0].reshape(-1,1080)\n",
    "G_data=RGB_data[:,:,:,1].reshape(-1,1080)\n",
    "B_data=RGB_data[:,:,:,2].reshape(-1,1080)\n",
    "RGB_input=np.concatenate((R_data,G_data,B_data),axis=1) #shape[size,3*1080]\n",
    "\n",
    "Sem_data=np.load(\"../Data/sem_data.npy\")\n",
    "Sem_input=np.transpose(Sem_data,(0,2,1,3))\n",
    "Ground_input=Sem_input[:,:,:,0].reshape(-1,1080)\n",
    "Objects_input=Sem_input[:,:,:,1].reshape(-1,1080)\n",
    "Building_input=Sem_input[:,:,:,2].reshape(-1,1080)\n",
    "Vegetation_input=Sem_input[:,:,:,3].reshape(-1,1080)\n",
    "Sky_input=Sem_input[:,:,:,4].reshape(-1,1080)\n",
    "Sem_input=np.concatenate((Ground_input,Objects_input,\n",
    "\t\t\t\t\t\t  Building_input,Vegetation_input,Sky_input),\n",
    "\t\t\t\t\t\t  axis=1)# shape[size,5*1080]\n",
    "\n",
    "n_samples=Sem_input.shape[0] # size \n",
    "############## Finish Load data ####################\n",
    "\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"Full\"):\n",
    "\tnetwork_architecture_Full = \\\n",
    "\t\tdict(n_hidden_recog_1=50, # 1st layer encoder neurons\n",
    "\t\t n_hidden_recog_2=50, # 2nd layer encoder neurons\n",
    "\t\t n_hidden_gener_1=50, # 1st layer decoder neurons\n",
    "\t\t n_hidden_gener_2=50, # 2nd layer decoder neurons\n",
    "\t\t n_input=200, # MNIST data input (img shape: 28*28)\n",
    "\t\t n_z=2)  # dimensionality of latent space\n",
    "\t#vae_Sem= VariationalAutoencoder(network_architecture_Sem,learning_rate=1e-4, batch_size=100)\n",
    "\tvae_Full=VariationalAutoencoder(network_architecture_Full,learning_rate=1e-4,batch_size=100)\n",
    "\n",
    "\n",
    "\n",
    "### Initialization\n",
    "init=tf.global_variables_initializer()\n",
    "sess=tf.Session(config=config)\n",
    "sess.run(init)\n",
    "\n",
    "###Load  other models \n",
    "saver_depth.restore(sess,\"vae_models/depth_5_epochs/model\")\n",
    "print(\"loaded model weights from \"+\"models/depth_5_epochs/model\")\n",
    "\n",
    "saver_rgb.restore(sess,\"vae_models/RGB_1_epochs/model\")\n",
    "print(\"loaded model weights from \"+\"models/RGB_1_epochs/model\")\n",
    "\n",
    "saver_Sem.restore(sess,\"vae_models/sem_1_epochs/model\")\n",
    "print(\"loaded model weights from \"+\"models/sem_1_epochs/model\")\n",
    "\n",
    "\n",
    "###Build data for full model \n",
    "z_depth=sess.run(vae_depth.z_mean,feed_dict={vae_depth.x:Depth_input})\n",
    "z_rgb=sess.run(vae_rgb.z_mean,feed_dict={vae_rgb.x:RGB_input})\n",
    "z_sem=sess.run(vae_Sem.z_mean,feed_dict={vae_Sem.x:Sem_input})\n",
    "#z_in is the data required \n",
    "z_in=np.concatenate((z_rgb,z_depth,z_sem),axis=1)\n",
    "\n",
    "\n",
    "######################## variables list #########################\n",
    "listvar4=vae_Full.network_weights\n",
    "var_Full=(list(listvar4['weights_recog'].values())\n",
    "\t+list(listvar4['biases_recog'].values())\n",
    "\t+list(listvar4['weights_gener'].values())\n",
    "\t+list(listvar4['biases_gener'].values()))\n",
    "saver_Full=tf.train.Saver(var_Full)\n",
    "\n",
    "\n",
    "train_new_model=False\n",
    "if train_new_model:    \n",
    "\tvae_Full.train(batch_size=100, training_epochs=1)\n",
    "\tsaver_Full.save(sess,\"vae_models/full_1_epochs/model\")\n",
    "\tprint(\"saved the vae model weights to \"+\"models/full_1_epochs/model\")\n",
    "else:\n",
    "\tsaver_Full.restore(sess,\"vae_models/full_1_epochs/model\")\n",
    "\tprint(\"loaded the vae model weights from\"+\"models/full_1_epochs/model\")\n",
    "\n",
    "\tz_out=sess.run(vae_Full.x_reconstr_mean,feed_dict={vae_Full.x:z_in[0:100,:]})\n",
    "\tz_out_rgb,z_out_depth,z_out_sem=np.split(z_out, [50,100],axis=1)\n",
    "\trgb_out=sess.run(vae_rgb.x_reconstr_mean,feed_dict={vae_rgb.z:z_out_rgb})# shape [size,3240]\n",
    "\tdepth_image=sess.run(vae_depth.x_reconstr_mean,feed_dict={vae_depth.z:z_out_depth})# shape [size,1080]\n",
    "\tsem_out=sess.run(vae_Sem.x_reconstr_mean,feed_dict={vae_Sem.z:z_out_sem})# shape[size,5400]\n",
    "\n",
    "\tred_out,green_out,blue_out=np.split(rgb_out,3,axis=1)\n",
    "\tRGB_image=np.dstack((red_out,green_out,blue_out))\n",
    "\n",
    "\tG_out,O_out,V_out,B_out,S_out=np.split(sem_out,5,axis=1)\n",
    "\tSem_image=np.dstack((G_out,O_out,V_out,B_out,S_out))\n",
    "\tplt.imshow(np.reshape(depth_image[0],(18,60)))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
